<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://fuyunfei.github.io</id>
    <title>皇后大道中</title>
    <updated>2020-07-12T07:12:19.968Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://fuyunfei.github.io"/>
    <link rel="self" href="https://fuyunfei.github.io/atom.xml"/>
    <subtitle>皇后大道西</subtitle>
    <logo>https://fuyunfei.github.io/images/avatar.png</logo>
    <icon>https://fuyunfei.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 皇后大道中</rights>
    <entry>
        <title type="html"><![CDATA[DDPG]]></title>
        <id>https://fuyunfei.github.io/post/ddpg/</id>
        <link href="https://fuyunfei.github.io/post/ddpg/">
        </link>
        <updated>2020-07-12T02:44:32.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://fuyunfei.github.io/post-images/1594521897525.png" alt="" loading="lazy"></figure>
<h3 id="为什么需要-target-网络">为什么需要 target 网络.</h3>
<h3 id="on-line-vs-off-line">on-line vs off-line</h3>
<h3 id="td-loss-的原理">TD loss 的原理</h3>
<p>1、critic网络更新<br>
critic网络用于值函数近似,更新方式与DQN中的类似.</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi mathvariant="normal">target</mi><mo>⁡</mo><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi>π</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><msup><mi>θ</mi><mo>−</mo></msup><mo fence="true">)</mo></mrow><mo separator="true">;</mo><msup><mi>ω</mi><mo>−</mo></msup><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mtext>Loss</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo fence="true">(</mo><msub><mi mathvariant="normal">target</mi><mo>⁡</mo><mi>t</mi></msub><mo>−</mo><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\operatorname{target}_{t} &amp;=R_{t+1}+\gamma Q\left(S_{t+1}, \pi\left(S_{t+1} ; \theta^{-}\right) ; \omega^{-}\right) \\
\text {Loss} &amp;=\frac{1}{N} \sum_{t=1}^{N}\left(\operatorname{target}_{t}-Q\left(S_{t}, a_{t} ; \omega\right)\right)^{2}
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.905449000000001em;vertical-align:-2.2027245000000004em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.7027245000000004em;"><span style="top:-5.681060500000001em;"><span class="pstrut" style="height:3.828336em;"></span><span class="mord"><span class="mop"><span class="mop"><span class="mord mathrm">t</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">e</span><span class="mord mathrm">t</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18641599999999994em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.1927244999999997em;"><span class="pstrut" style="height:3.828336em;"></span><span class="mord"><span class="mord text"><span class="mord">Loss</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.2027245000000004em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.7027245000000004em;"><span style="top:-5.681060500000001em;"><span class="pstrut" style="height:3.828336em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span><span style="top:-3.1927244999999997em;"><span class="pstrut" style="height:3.828336em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mop"><span class="mop"><span class="mord mathrm">t</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">e</span><span class="mord mathrm">t</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18641599999999994em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">−</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.954008em;"><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.2027245000000004em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>然后使用梯度下降法进行更新. 注意,actor和critic都使用了target网络来计算target.</p>
<p>2、actor网络更新<br>
actor网络用于参数化策略. 这里涉及到强化学习中一个非常重要的極念：策略梯度Policy Gradient.<br>
如何评价一个策略的好坏? 首先我们要有一个目标, 称为policy objective function,记为 J( <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> . 我们希望求得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>取得最 大值.  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 对的导数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\nabla_{\theta} J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 即为策略梯度.</p>
<p>策略梯度这一块可以分为四种情况分别讨论：stochastic on-policy, stochastic off-policy, deterministic on-policy 和 deterministic off-policy. David Silver的课程中详细的介绍了第一种. DPG论文的第二部分讲了第二种,第四部分讲了第三四种. 由于DDPG 中的策路是deterministic的,本文只介绍最后两种.</p>
<p>直观上来说, 我们应该朝着使得值函数Q值增大的方向去更新策略的参数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>.<br>
记策略为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mo>=</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">a=\pi_{\theta}(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span> <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mrow><mo fence="true">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><msub><mo>∫</mo><msub><mi>s</mi><mi>s</mi></msub></msub><msup><mi>d</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo>)</mo><mi>Q</mi><mrow><mo fence="true">(</mo><mi>s</mi><mo separator="true">,</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo><mo fence="true">)</mo></mrow><mi>d</mi><mi>s</mi><mo>=</mo><msub><mi>E</mi><mrow><mi>s</mi><mo>∼</mo><msup><mi>d</mi><mi>p</mi></msup></mrow></msub><mrow><mo fence="true">[</mo><mi>Q</mi><mrow><mo fence="true">(</mo><mi>s</mi><mo separator="true">,</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo><mo fence="true">)</mo></mrow><mo fence="true">]</mo></mrow><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">J\left(\pi_{\theta}\right)=\int_{s_{s}} d^{\pi}(s) Q\left(s, \pi_{\theta}(s)\right) d s=E_{s \sim d^{p}}\left[Q\left(s, \pi_{\theta}(s)\right)\right],</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.26092em;vertical-align:-0.45592em;"></span><span class="mop"><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.05442800000000003em;"><span style="top:-2.34418em;margin-left:-0.19445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.45592em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span></span></span></span> 有以下定理:</p>
<p>Deterministic Policy Gradient Theorem:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>J</mi><mrow><mo fence="true">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><msub><mrow><msub><mo>∫</mo><mi>s</mi></msub><msup><mi>d</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo>)</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo><msub><mi mathvariant="normal">∇</mi><mi>a</mi></msub><msup><mi>Q</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo fence="true">∣</mo></mrow><mrow><mi>a</mi><mo>=</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow></msub><mi>d</mi><mi>s</mi><mo>=</mo><msub><mi>E</mi><mrow><mi>s</mi><mo>∼</mo><msup><mi>d</mi><mo>∗</mo></msup></mrow></msub><mrow><mo fence="true">[</mo><msub><mrow><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo><msub><mi mathvariant="normal">∇</mi><mi>a</mi></msub><msup><mi>Q</mi><mi>π</mi></msup><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo><mo fence="true">∣</mo></mrow><mrow><mi>a</mi><mo>=</mo><msub><mi>π</mi><mi>ρ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow></msub><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\nabla_{\theta} J\left(\pi_{\theta}\right)=\left.\int_{s} d^{\pi}(s) \nabla_{\theta} \pi_{\theta}(s) \nabla_{a} Q^{\pi}(s, a)\right|_{a=\pi_{\theta}(s)} d s=E_{s \sim d^{*}}\left[\left.\nabla_{\theta} \pi_{\theta}(s) \nabla_{a} Q^{\pi}(s, a)\right|_{a=\pi_{\rho}(s)}\right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.6487em;vertical-align:-1.1747199999999998em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.6105579999999999em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.47398em;"><span style="top:-1.65598em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.26198em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-2.86798em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span><span style="top:-3.47398em;"><span class="pstrut" style="height:2.606em;"></span><span class="delimsizinginner delim-size1"><span>∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500199999999999em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.4747199999999998em;"><span style="top:-1.7002800000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1747199999999998em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">∣</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2252999999999999em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ρ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.49701999999999996em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span></span></span></span></span></p>
<p>确定性策略梯度定理提供了更新确定性策略的方法. 将此方法用到Actor-Critic算法中：</p>
<p>(1) On-Policy Deterministic Actor-Critic</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext> TD Error: </mtext><msub><mi>δ</mi><mi>t</mi></msub><mo>=</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mo>−</mo><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext> 更新Critic: </mtext><mi mathvariant="normal">Δ</mi><mi>ω</mi><mo>=</mo><msub><mi>α</mi><mi>ω</mi></msub><mo>⋅</mo><msub><mi>δ</mi><mi>t</mi></msub><mo>⋅</mo><mi mathvariant="normal">∇</mi><mi>ω</mi><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mtext> (SARSA) </mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{l}
\text { TD Error: } \delta_{t}=R_{t+1}+\gamma Q\left(S_{t+1}, a_{t+1} ; \omega\right)-Q\left(S_{t}, a_{t} ; \omega\right) \\
\text { 更新Critic: } \Delta \omega=\alpha_{\omega} \cdot \delta_{t} \cdot \nabla \omega Q\left(S_{t}, a_{t} ; \omega\right) \text { (SARSA) }
\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4000000000000004em;vertical-align:-0.9500000000000004em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord"> TD Error: </span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">更新</span><span class="mord">Critic: </span></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">∇</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord"> (SARSA) </span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<p>更新actor: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo>=</mo><msub><mrow><msub><mi>α</mi><mi>θ</mi></msub><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><msub><mi mathvariant="normal">∇</mi><mi>a</mi></msub><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow><mrow><mi>a</mi><mo>=</mo><msub><mi>π</mi><mi>s</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\Delta \theta=\left.\alpha_{\theta} \cdot \nabla_{\theta} \pi_{\theta}\left(S_{t}\right) \nabla_{a} Q\left(S_{t}, a_{t} ; \omega\right)\right|_{a=\pi_{s}(s)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2247em;vertical-align:-0.47469999999999996em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2253em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.47469999999999996em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>(2) Off-Policy Deterministic Actor-Critic</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> TD Error: </mtext><msub><mi>δ</mi><mi>t</mi></msub><mo>=</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mo>−</mo><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text { TD Error: } \delta_{t}=R_{t+1}+\gamma Q\left(S_{t+1}, \pi_{\theta}\left(S_{t+1}\right) ; \omega\right)-Q\left(S_{t}, a_{t} ; \omega\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord text"><span class="mord"> TD Error: </span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<p>更新critic: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>ω</mi><mo>=</mo><msub><mi>α</mi><mi>ω</mi></msub><mo>⋅</mo><msub><mi>δ</mi><mi>t</mi></msub><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ω</mi></msub><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Delta \omega=\alpha_{\omega} \cdot \delta_{t} \cdot \nabla_{\omega} Q\left(S_{t}, a_{t} ; \omega\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.59445em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> (Q-Learning)<br>
更新actor: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>θ</mi><mo>=</mo><msub><mrow><msub><mi>α</mi><mi>θ</mi></msub><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><msub><mi>π</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><msub><mi mathvariant="normal">∇</mi><mi>a</mi></msub><mi>Q</mi><mrow><mo fence="true">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo separator="true">;</mo><mi>ω</mi><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow><mrow><mi>a</mi><mo>=</mo><msub><mi>π</mi><mi>θ</mi></msub><mo>(</mo><mi>s</mi><mo>)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">\Delta \theta=\left.\alpha_{\theta} \cdot \nabla_{\theta} \pi_{\theta}\left(S_{t}\right) \nabla_{a} Q\left(S_{t}, a_{t} ; \omega\right)\right|_{a=\pi_{\theta}(s)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">Δ</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2247em;vertical-align:-0.47469999999999996em;"></span><span class="minner"><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">Q</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2253em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">=</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.47469999999999996em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>注意,在off-policy中,用于生成行为数据的策略和用于评估的策路不是同一个策路,也就是说,智能体实际上采取的action <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span> 不是由<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span>生成的. 假设它是由 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 生成的. 在DDPG中, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span> 策略是在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span> 第略上增加了随机鸣声random process,用来保证探索 exploration.</p>
<p>理论上,这里引入了两种bias：一个是Deterministic Policy Gradient Theorem中的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">Q(s, a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span></span></span></span>, 我们实际上用的是它的近似函数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo>(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">;</mo><mi>ω</mi><mo>)</mo><mo separator="true">;</mo></mrow><annotation encoding="application/x-tex">Q(s, a ; \omega) ;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mpunct">;</span></span></span></span> 另一个是在off-policy中,行为策路与评估策路不同,理论上是需要引入importance sampling来进行修正的. 实际上,这两个bias都通过蒲足了一个定理的条件来得以保证. 详见Compatible Function Approximation.</p>
<pre><code class="language-code">import gym
import random
import collections
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

#Hyperparameters
lr_ac        = 0.0005
lr_q         = 0.001
gamma        = 0.99
batch_size   = 32
buffer_limit = 50000
tau          = 0.005 # for target network soft update

class ReplayBuffer():
    def __init__(self):
        self.buffer = collections.deque(maxlen=buffer_limit)

    def put(self, transition):
        self.buffer.append(transition)
    
    def sample(self, n):
        mini_batch = random.sample(self.buffer, n)
        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []

        for transition in mini_batch:
            s, a, r, s_prime, done_mask = transition
            s_lst.append(s)
            a_lst.append([a])
            r_lst.append([r])
            s_prime_lst.append(s_prime)
            done_mask_lst.append([done_mask])
        
        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst, dtype=torch.float), \
               torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \
               torch.tensor(done_mask_lst)
    
    def size(self):
        return len(self.buffer)

class AcNet(nn.Module):
    def __init__(self):
        super(AcNet, self).__init__()
        self.fc1 = nn.Linear(3, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc_ac = nn.Linear(64, 1)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        ac = torch.tanh(self.fc_ac(x))*2 # Acltipled by 2 because the action space of the Pendulum-v0 is [-2,2]
        return ac

class QNet(nn.Module):
    def __init__(self):
        super(QNet, self).__init__()
        
        self.fc_s = nn.Linear(3, 64)
        self.fc_a = nn.Linear(1,64)
        self.fc_q = nn.Linear(128, 32)
        self.fc_3 = nn.Linear(32,1)

    def forward(self, x, a):
        h1 = F.relu(self.fc_s(x))
        h2 = F.relu(self.fc_a(a))
        cat = torch.cat([h1,h2], dim=1)
        q = F.relu(self.fc_q(cat))
        q = self.fc_3(q)
        return q

class OrnsteinUhlenbeckNoise:
    def __init__(self, ac):
        self.theta, self.dt, self.sigma = 0.1, 0.01, 0.1
        self.ac = ac
        self.x_prev = np.zeros_like(self.ac)

    def __call__(self):
        x = self.x_prev + self.theta * (self.ac - self.x_prev) * self.dt + \
                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.ac.shape)
        self.x_prev = x
        return x
      
def train(ac, ac_target, q, q_target, memory, q_optimizer, ac_optimizer):
    s,a,r,s_prime,done_mask  = memory.sample(batch_size)
    
    target = r + gamma * q_target(s_prime, ac_target(s_prime))
    q_loss = F.smooth_l1_loss(q(s,a), target.detach())
    q_optimizer.zero_grad()
    q_loss.backward()
    q_optimizer.step()
    
    ac_loss = -q(s,ac(s)).mean() # That's all for the policy loss.
    ac_optimizer.zero_grad()
    ac_loss.backward()
    ac_optimizer.step()
    
def soft_update(net, net_target):
    for param_target, param in zip(net_target.parameters(), net.parameters()):
        param_target.data.copy_(param_target.data * (1.0 - tau) + param.data * tau)
    
def main():
    env = gym.make('Pendulum-v0')
    memory = ReplayBuffer()

    q, q_target = QNet(), QNet()
    q_target.load_state_dict(q.state_dict())
    ac, ac_target = AcNet(), AcNet()
    ac_target.load_state_dict(ac.state_dict())

    score = 0.0
    print_interval = 20

    ac_optimizer = optim.Adam(ac.parameters(), lr=lr_ac)
    q_optimizer  = optim.Adam(q.parameters(), lr=lr_q)
    ou_noise = OrnsteinUhlenbeckNoise(ac=np.zeros(1))

    for n_epi in range(10000):
        s = env.reset()
        # actor将这个状态转换过程(transition): (st,at,rt，st+1) 存入replay memory buffer R中，作为训练online网络的数据集。
        for t in range(300): # maxiacm length of episode is 200 for Pendulum-v0
            a = ac(torch.from_numpy(s).float()) 
            a = a.item() + ou_noise()[0]
            s_prime, r, done, info = env.step([a])
            memory.put((s,a,r/100.0,s_prime,done))
            score +=r
            s = s_prime

            if done:
                break              
                
        if memory.size()&gt;2000:
            for i in range(10):
                train(ac, ac_target, q, q_target, memory, q_optimizer, ac_optimizer)
                soft_update(ac, ac_target)
                soft_update(q,  q_target)
        
        if n_epi%print_interval==0 and n_epi!=0:
            print(&quot;# of episode :{}, avg score : {:.1f}&quot;.format(n_epi, score/print_interval))
            score = 0.0

    env.close()

if __name__ == '__main__':
    main()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RL 00]]></title>
        <id>https://fuyunfei.github.io/post/rl-00/</id>
        <link href="https://fuyunfei.github.io/post/rl-00/">
        </link>
        <updated>2020-07-11T09:35:02.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists">課程撥放清單</a></p>
<h2 id=""><a href="#A3C" title="A3C"></a>A3C</h2>
<p><a href="https://www.youtube.com/watch?v=O79Ic8XBzvw&amp;list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9&amp;index=23">課程連結</a></p>
<h3 id="-2"><a href="#Approaches" title="Approaches"></a>Approaches</h3>
<figure data-type="image" tabindex="1"><img src="https://i.imgur.com/dV9qlUw.png" alt="" loading="lazy"></figure>
<p>Deep Reinforcement Learning分為兩大類：</p>
<ol>
<li>Model-free Approach
<ul>
<li>適用於無法窮舉的環境</li>
<li>兩大類：
<ul>
<li>Policy-based
<ul>
<li>訓練一個Actor，負責執行動作。</li>
</ul>
</li>
<li>Value-based
<ul>
<li>訓練一個Critic，負責對目前的狀況給予評價。</li>
</ul>
</li>
<li>也可以混合使用
<ul>
<li>Actor + Critic</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Model-based Approach
<ul>
<li>Agent採取一個動作之後會預測接下來發生什麼事。</li>
<li>AlphaGo內就有使用到Model-based，下一步棋之後計算勝率。</li>
<li>限制較多，使用之前要對環境先建立模型，因此可以預測環境下一步會發生的事情。
<ul>
<li>如果是電玩場景，環境無法窮舉，雖然圍棋的下一步變化多端，但還是可以窮舉。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>目前(2017年)較多使用的是A3C，而不是DQN。</p>
<h3 id="-3"><a href="#On-policy-vs-Off-policy" title="On-policy-vs-Off-policy"></a>On-policy v.s. Off-policy</h3>
<figure data-type="image" tabindex="2"><img src="https://i.imgur.com/h8rQnrU.png" alt="" loading="lazy"></figure>
<p>On-policy，要學習的Agent跟與環境互動的Agent是同一個Agent。</p>
<p>Off-policy，要學習的Agent跟與環境互動的Agent並不是同一個Agent，意味著要學習的那個Agent是在一邊看著另一個Agent與環境互動，以它們互動的狀況來進行學習。使用這個方法要特別注意兩個Agent之間的差距。好比你看著Joradn空間停留三秒，但是你上場的時候根本學不起來。</p>
<h3 id="-4"><a href="#Actor-is-a-Neural-network" title="Actor-is-a-Neural-network"></a>Actor is a Neural network</h3>
<figure data-type="image" tabindex="3"><img src="https://i.imgur.com/Norv406.png" alt="" loading="lazy"></figure>
<p><a href="https://arxiv.org/abs/1602.01783">論文連結_Asynchronous Methods for Deep Reinforcement Learning</a></p>
<p>A3C=Asynchronous Advantage Actor-Critic</p>
<p>Actor是一個Neural Network：</p>
<ul>
<li>input：observation，可以是vector，也可以是matrix。</li>
<li>output：你有那些可以被採取的action</li>
</ul>
<p>以遊戲來說明的話，observation就是你看到的遊戲畫面，而output的action就是機器看到observation之後決定的動作，左、右、開火…等，每一個action都會有一個分數，你可以用argmax的方式看那一個機率最高就採用，或者可以用隨機選擇。</p>
<p>要讓Actor可以採取連續動作也是可行的，所謂的連續動作指的是，假設機器人是一個多軸訊號控制，那你要一次針對多個軸做訊號輸出，假設有十軸，那你的輸出就會是十維的向量。</p>
<h3 id="-5"><a href="#Actor---Goodness-of-an-Actor" title="Actor---Goodness-of-an-Actor"></a>Actor - Goodness of an Actor</h3>
<figure data-type="image" tabindex="4"><img src="https://i.imgur.com/IWMZ2wP.png" alt="" loading="lazy"></figure>
<p>有了Actor，就需要衡量這個Actor有多好。假設每一個Actor就是一個function-π(s)π(s)，上面已經定義它是一個<code>nn</code>，它的參數就是πθπθ。</p>
<p>接下來我們拿這個Actor去玩遊戲，有了一連串的操作記錄，記錄著state-SS，action-aa，reward-rr。遊戲的總體reward我們寫為R=∑Tt=1rtR=∑t=1Trt，記錄每一個時間點tt的reward。</p>
<p>即使拿相同的Actor去玩兩次遊戲，結果不一定會是一樣，這有兩個理由：</p>
<ol>
<li>有時候Actor可能是隨機性的，即使相同的observation也不一定會有一樣的output。
<ul>
<li>上面提到過，我們可以將output視為distribution，再從裡面sample出一個action。</li>
</ul>
</li>
<li>即使Actor看到相同的observation有一樣的action，但是遊戲中的AI也存在著隨機性。</li>
</ol>
<p>我們可以定義expected total reward(期望值)為¯RθπR¯θπ，也就是參數為θπθπ的情況下，我們期望得到的reward有多少。</p>
<p>現在，我們可以拿這個¯RθπR¯θπ來估測Actor有多好。</p>
<h3 id="-6"><a href="#Actor---Policy-Gradient" title="Actor---Policy-Gradient"></a>Actor - Policy Gradient</h3>
<figure data-type="image" tabindex="5"><img src="https://i.imgur.com/S9Imy7q.png" alt="" loading="lazy"></figure>
<p>有了評估Actor的定義，就可以做Policy Gradient，相關推導在之前課程有，可以回頭看。</p>
<p>直觀說明如下：</p>
<ul>
<li>θπ′=θπ+η∇¯Rθπθπ′=θπ+η∇R¯θπ
<ul>
<li>η∇¯Rθπη∇R¯θπ：計算θπθπ對expected total reward的gradient，以此更新θπθπ得到θπ′θπ′</li>
</ul>
</li>
<li>∇¯Rθπ≈1N∑Nn=1R(τn)∇logP(τn|θπ)=1N∑Nn=1R(τn)∑Tnt=1∇logp(ant|snt,θπ)=1N∑Nn=1∑Tnt=1R(τn)∇logp(ant|snt,θπ)∇R¯θπ≈1N∑n=1NR(τn)∇log⁡P(τn|θπ)=1N∑n=1NR(τn)∑t=1Tn∇log⁡p(atn|stn,θπ)=1N∑n=1N∑t=1TnR(τn)∇log⁡p(atn|stn,θπ)</li>
</ul>
<p>上面做的事簡單的說就是，假設在某次的遊戲記錄τnτn中，Actor看到某一個state-sntstn而執行某一個action-antatn。整個遊戲玩完之後它的reward-R(τn)R(τn)是好的，那機器就會試著去更新參數-θθ讓p(ant|snt)p(atn|stn)出現的機率變大，反之如果最後的reward-R(τn)R(τn)是不好的，那機器就會試著降低p(ant|snt)p(atn|stn)出現的機率。</p>
<p>要注意到一點是，我們考慮的不是單一個state-action得到的reward，而是整場遊戲所得到的reward。</p>
<h3 id="-7"><a href="#Critic" title="Critic"></a>Critic</h3>
<figure data-type="image" tabindex="6"><img src="https://i.imgur.com/5sqnZd8.png" alt="" loading="lazy"></figure>
<p>Critic本身是不做事，它的角色就是給定一個actor-ππ，然後衡量這個actor有多好或多不好。Critic有很多種，這次課程說明的是State value function-Vπ(s)Vπ(s)：</p>
<ul>
<li>給定一個actor-ππ</li>
<li>看到某一個observation(state)-ss，然後評估接下來一直到遊戲結束，我們會得到的reward有多大。</li>
<li>這個期望值即為Vπ(s)Vπ(s)，為數值。</li>
</ul>
<p>以小蜜蜂之類的遊戲來看，遊戲初始怪物多，那Vπ(s)Vπ(s)所得較大，而後期因為怪物殺的差不多了，因此Vπ(s)Vπ(s)所得會較小。</p>
<p>從這邊可以發現，State value function是與actor有關，因此定義之前一定要先給定actor。</p>
<h3 id="-8"><a href="#Critic1" title="Critic1"></a>Critic</h3>
<figure data-type="image" tabindex="7"><img src="https://i.imgur.com/aDuXlfV.png" alt="" loading="lazy"></figure>
<p>將阿光想為actor，而佐為是critic，過往阿光較弱的時候下大馬步飛那可能會有較大的機會出錯，因此是不好的，而變強之後的阿光反而應該是走大馬步飛而不是小馬步飛。</p>
<p>這個案例說明著不同actor即使遇到相同的state也會有不同的結果。</p>
<h3 id="-9"><a href="#How-to-estimate-Vpis" title="How-to-estimate-Vpis"></a>How to estimate Vπ(s)Vπ(s)</h3>
<figure data-type="image" tabindex="8"><img src="https://i.imgur.com/07opdIO.png" alt="" loading="lazy"></figure>
<p>有兩種方式可以評估Vπ(s)Vπ(s)：</p>
<ol>
<li>Monte-Carlo
<ul>
<li>讓Critic觀察目前的actor-ππ的行為，讓actor-ππ與環境互動，然後統計actor-ππ會得到的reward</li>
<li>舉例來說，它在看到sasa之後會得到的reward-GaGa，注意到，這邊所統計的reward是一直到遊戲結束的reward總合，這樣子機器才有辦法看的長遠。</li>
<li>因此，機器要學習的就是當看到sasa的時候，其Vπ(s)Vπ(s)要跟GaGa愈接近愈好。</li>
</ul>
</li>
</ol>
<h3 id="-10"><a href="#How-to-estimate-Vpis1" title="How-to-estimate-Vpis1"></a>How to estimate Vπ(s)Vπ(s)</h3>
<figure data-type="image" tabindex="9"><img src="https://i.imgur.com/VZtWq33.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>Temporal-difference
<ul>
<li>我們只看整個互動的其中一小段，某一個stst採取什麼樣的atat而得到多少的rtrt…</li>
<li>假設我們已經知道Vπ(st)Vπ(st)，它跟下一個時間點st+1st+1之間差了一個rtrt
<ul>
<li>即Vπ(st)+rt=Vπ(st+1)Vπ(st)+rt=Vπ(st+1)</li>
</ul>
</li>
<li>機器要學習的就是，Vπ(st)−Vπ(st+1)Vπ(st)−Vπ(st+1)要愈接近rtrt愈好。</li>
</ul>
</li>
</ol>
<p>這麼做的理由在於，有些情況下我們無法計算整個過程的reward，好比有一個機器人，它沒有開始與結束，就只有不斷的與環境互動，這種情況之下就無法使用Monte-Carlo來計算，只能取片段來估測而以。</p>
<h3 id="-11"><a href="#MC-vs-TD" title="MC-vs-TD"></a>MC v.s. TD</h3>
<figure data-type="image" tabindex="10"><img src="https://i.imgur.com/fdA8E1Q.png" alt="" loading="lazy"></figure>
<p>MC</p>
<p>TD</p>
<p>考慮累計reward-GG</p>
<p>考慮單一reward-rr</p>
<p>variance較大</p>
<p>variance較小</p>
<p>unbiased</p>
<p>May be biased</p>
<p>這非常直觀，如果每一個step的reward都加入一個noise，TD僅考慮一個step，只加一個noise，而MC是考慮整個step，加入的noise自然較大，因此會擁有較大的Variance。</p>
<h3 id="-12"><a href="#MC-vs-TD1" title="MC-vs-TD1"></a>MC v.s. TD</h3>
<figure data-type="image" tabindex="11"><img src="https://i.imgur.com/wK2Aq6G.png" alt="" loading="lazy"></figure>
<p>這邊案例給出兩個不同模式下的差異，假設你是一個critic，你有上表所列的8筆記錄，其中sasa僅出現1次，其reward=0。</p>
<p>此案例的Vπ(sb)Vπ(sb)很直觀的就是出現8次，其reward為6，期望值為6868，但Vπ(sa)Vπ(sa)就會依你所採用的方式不同而有不同的答案：</p>
<ul>
<li>Monte-Carlo：這種情況下，就是統計它的期望值，僅1次且reward=0，因此Vπ(sa)=0Vπ(sa)=0</li>
<li>Temporal-difference：Vπ(sa)+r=Vπ(sb)Vπ(sa)+r=Vπ(sb)，因此Vπ(sa)=34Vπ(sa)=34</li>
</ul>
<p>實際應該取決於你的真實環境，如果sbsb是一個不受sasa干擾的情況，那sb=34sb=34，但如果是會受干擾的話，那除非sbsb是放在互動的開頭那才會有reward。</p>
<h3 id="-13"><a href="#Actor-Critic" title="Actor-Critic"></a>Actor-Critic</h3>
<figure data-type="image" tabindex="12"><img src="https://i.imgur.com/cuX2Cka.png" alt="" loading="lazy"></figure>
<p>現在我們也有Critic，利用Critic來估測Actor：</p>
<ol>
<li>你有一個Policy-ππ</li>
<li>利用ππ與環境互動收集到很多的資料</li>
<li>選擇利用TD或MC的方式來學到Vπ(s)Vπ(s)</li>
<li>依據Vπ(s)Vπ(s)來找到新的π′π′</li>
<li>再利用π′π′與環境互動</li>
<li>⋮⋮</li>
</ol>
<h3 id="-14"><a href="#Advantage-Actor-Critic" title="Advantage-Actor-Critic"></a>Advantage Actor-Critic</h3>
<figure data-type="image" tabindex="13"><img src="https://i.imgur.com/yJvzmtP.png" alt="" loading="lazy"></figure>
<p>θπ′=θπ+η∇¯Rθπθπ′=θπ+η∇R¯θπ</p>
<ul>
<li>η∇¯Rθπη∇R¯θπ：計算θπθπ對expected total reward的gradient，以此更新θπθπ得到θπ′θπ′</li>
</ul>
<p>∇¯Rθπ=1N∑Nn=1∑Tnt=1R(τn)∇logp(ant|snt,θπ)∇R¯θπ=1N∑n=1N∑t=1TnR(τn)∇log⁡p(atn|stn,θπ)</p>
<ul>
<li>R(τn)R(τn)：在第nn次的互動中得到多少的reward</li>
<li>原本是讓Actor自己統計自己在整個互動中得到的reward，現在我們要改成讓Critic來幫忙算
<ul>
<li>建議作法：rnt−(Vπ(snt)−Vπ(snt+1))rtn−(Vπ(stn)−Vπ(st+1n))
<ul>
<li>這只是A3C論文中的其中一種作法</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>原本Actor是針對整個過程的reward做計算，得到RR，但如果採用A3C的話作法如下：</p>
<ul>
<li>rnt−(Vπ(snt)−Vπ(snt+1))rtn−(Vπ(stn)−Vπ(st+1n))
<ul>
<li>rntrtn：在state-sntstn的時候採取action-antatn會得到的reward-rntrtn</li>
<li>(Vπ(snt)−Vπ(snt+1))(Vπ(stn)−Vπ(st+1n))：這個項目是根據critic估測出來的。
<ul>
<li>依據目前的Policy-ππ，其Vπ(snt)Vπ(stn)與Vπ(snt+1))Vπ(st+1n))的accumulate value差距有多少</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Advantage Actor-Critic告訴我們的就是，當Advantage function的值是正的，那就要增加採取action-antatn的機率，反之為負則減少。</p>
<h3 id="-15"><a href="#Advantage-Actor-Critic1" title="Advantage-Actor-Critic1"></a>Advantage Actor-Critic</h3>
<figure data-type="image" tabindex="14"><img src="https://i.imgur.com/E0yjeJE.png" alt="" loading="lazy"></figure>
<p>實作中的小技巧：</p>
<ol>
<li>critic-Vπ(s)Vπ(s)與actor-π(s)π(s)的參數是可以共享的
<ul>
<li>如果是玩遊戲，那輸入的前幾層可能利用CNN，這部份是可以共用的</li>
</ul>
</li>
<li>論文中提到，希望actor output的entropy是大的，以entropy來做正規化
<ul>
<li>讓actor output的distribution不要過於集中，而是平滑。這麼做的好處是讓actor在與環境互動的時候能多點探索，過於集中可能就只會回應幾個固定模式。</li>
</ul>
</li>
</ol>
<h3 id="-16"><a href="#Asynchronous" title="Asynchronous"></a>Asynchronous</h3>
<figure data-type="image" tabindex="15"><img src="https://i.imgur.com/eZogKsA.png" alt="" loading="lazy"></figure>
<p><a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2#.68x6na7o9">image source_Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)</a></p>
<p>Asynchronous的意思指，我們有一個共同參數θ1θ1，然後同時有很多actor(簡報上的Worker)與環境互動，每一個Worker都包含著一個actor與critic：</p>
<ol>
<li>首先，Worker先將global parameters-θ1θ1複製過來</li>
<li>利用複製過來的參數θ1θ1與環境互動</li>
<li>計算更新actor與critic的參數的梯度</li>
<li>資訊送回global parameters更新</li>
</ol>
<p>這個過程中其它的Worker也同時與環境做互動，其它的Worker也有它們的參數更新回傳至global parameters，因此，也許Worker回傳的global的時候它已經不是原始的θ1θ1而是θ2θ2，雖然這麼聽起來有點怪，但實作上確實可行。這麼做的好處是可以增加訓練的速度。</p>
<h3 id="-17"><a href="#Pathwise-Derivative-Policy-Gradient" title="Pathwise-Derivative-Policy-Gradient"></a>Pathwise Derivative Policy Gradient</h3>
<figure data-type="image" tabindex="16"><img src="https://i.imgur.com/r7YViPq.png" alt="" loading="lazy"></figure>
<p>Pathwise Derivative Policy Gradient與Actor-critic的差異在於，Actor-critic只會回應好壞，但是Pathwise Derivative Policy Gradient是會有建議的。</p>
<h3 id="-18"><a href="#Anthor-Critic" title="Anthor-Critic"></a>Anthor Critic</h3>
<figure data-type="image" tabindex="17"><img src="https://i.imgur.com/QZTGiza.png" alt="" loading="lazy"></figure>
<p>這是一個與上面所介紹Critic不同的function，Qπ(s,a)Qπ(s,a)：</p>
<ul>
<li>輸入為state與action的pair</li>
<li>不同於Vπ(s)Vπ(s)僅考慮state之後計算期望的reward，Qπ(s,a)Qπ(s,a)考慮state與action來計算接下來可能得到的reward</li>
<li>輸出為scalar，告讓你接下來會得到的reward有多大</li>
</ul>
<p>如果你的action可以窮舉的話就可以讓QπQπ的輸入單純的只有state，而輸出的部份就可以帶action，每一個dimension都帶有一個action，每一個action會有多少的reward，但再次的說明，這只針對discrete action可行。</p>
<h3 id="-19"><a href="#Another-Way-to-use-Critic" title="Another-Way-to-use-Critic"></a>Another Way to use Critic</h3>
<figure data-type="image" tabindex="18"><img src="https://i.imgur.com/yoghjVy.png" alt="" loading="lazy"></figure>
<p>假設，Qπ(s,a)Qπ(s,a)的趨勢是如藍線般，很明顯的a1a1能得到的reward是低於a2a2的，這時候機器會讓a1a1出現的機率降低，而讓a2a2的機率增加。</p>
<p>但這會有一個問題，那就是機器對於沒有sample過的action，機器並不會知道該增加或是減少它出現的機率。圖示來看，紅線所能得到的reward是最好的，但沒有sample到的話，機器並不會知道，而且actor本身是有隨機性的，除了真的取樣取到，否則不會知道。這種問題在action是很大或者是continuous比較常見。</p>
<p>因此，有一種方法，基本上這個function-Qπ(s,a)Qπ(s,a)是我們所擬合出來的<code>nn</code>，因此我們是知道它的參數，既然知道它的參數那當然知道它的最高點在那。前提是假設這個<code>nn</code>的估測是準的。</p>
<p>當我們sample到aa的時候，只需要將它向左移得到a′a′，就可以得到較大的reward，而不用苦等某年某月某一天去sample到它，這種方式稱為Q-learning。</p>
<h3 id="-20"><a href="#Q-Learning" title="Q-Learning"></a>Q-Learning</h3>
<figure data-type="image" tabindex="19"><img src="https://i.imgur.com/StC38dH.png" alt="" loading="lazy"></figure>
<p>Q-learning與Actor-Critic類似：</p>
<ul>
<li>你有Policy-ππ</li>
<li>Policy-ππ與環境互動收集很多資料</li>
<li>利用收集到的資料估測Qπ(s,a)Qπ(s,a)
<ul>
<li>這邊我們估測的是QQ而不是VV，因為我們是借由QQ來產生Policy，而不是VV</li>
</ul>
</li>
<li>找一個比ππ還要好的新的π′π′</li>
</ul>
<p>註：說Policy的時候就是指Actor</p>
<h3 id="-21"><a href="#Q-Learning1" title="Q-Learning1"></a>Q-Learning</h3>
<figure data-type="image" tabindex="20"><img src="https://i.imgur.com/nP12Dvg.png" alt="" loading="lazy"></figure>
<p>所謂比ππ還要好的π′π′的定義是：</p>
<ul>
<li>對於所有的state而言，Vπ′(s)≥Vπ(s)Vπ′(s)≥Vπ(s)
<ul>
<li>Vπ(s)Vπ(s)：假設我們現在actor是ππ，在state-ss的時候，我們預期接下來的reward有多少</li>
<li>Vπ′(s)Vπ′(s)：假設我們現在actor是π′π′，在state-ss的時候，我們預期接下來的reward有多少</li>
<li>這意昧著不管現在的state是什麼，在actor為π′π′的情況下，它的reward都會比actor-ππ還要大</li>
</ul>
</li>
</ul>
<p>π′(s)=argmaxQπ(s,a)π′(s)=argmaxQπ(s,a)：</p>
<ul>
<li>state為給定，為actor的input</li>
<li>拿Q-function來看，那一個action可以給Q-function的值最大即為π′π′的Output</li>
</ul>
<p>兩點注意：</p>
<ol>
<li>π′π′本身沒有參數，參數是在Q-function(本身為<code>nn</code>)，要採取那一個action是由Q-function的參數決定。</li>
<li>不適用於action性質為continuous的情況，如果是連續函數，那代表我們需要用gradient ascent來求出最大值，每次都要計算一次，曠日費時。(後續說明)</li>
</ol>
<h3 id="-22"><a href="#Q-Learning2" title="Q-Learning2"></a>Q-Learning</h3>
<figure data-type="image" tabindex="21"><img src="https://i.imgur.com/G2edrbf.png" alt="" loading="lazy"></figure>
<p>現在要證明π′(s)=argmaxQπ(s,a)π′(s)=argmaxQπ(s,a)可以滿足Vπ′(s)≥Vπ(s)Vπ′(s)≥Vπ(s) for all state-ss這件事是對的：</p>
<ul>
<li>Vπ(s)=Qπ(s,π(s))Vπ(s)=Qπ(s,π(s))
<ul>
<li>Vπ(s)Vπ(s)：在state-ss，用actor-ππ與環境互動期望得到的reward</li>
<li>Qπ(s,π(s))Qπ(s,π(s))：在state-ss採取action-π(s)π(s)會得到的reward，如果actor為ππ，那它採取的action就是π(s)π(s)</li>
</ul>
</li>
<li>Vπ(s)=Qπ(s,π(s))≤maxaQπ(s,a)Vπ(s)=Qπ(s,π(s))≤maxaQπ(s,a)
<ul>
<li>Q-function不變情況下，窮舉所有可能的action-aa帶入Qπ(s,a)Qπ(s,a)。很明顯的，maxQπ(s,a)maxQπ(s,a)是一個upper bound。</li>
</ul>
</li>
<li>Vπ(s)=Qπ(s,π(s))≤maxaQπ(s,a)=Qπ(s,π′(s))Vπ(s)=Qπ(s,π(s))≤maxaQπ(s,a)=Qπ(s,π′(s))
<ul>
<li>那一個actor會採取一個讓Qπ(s,a)Qπ(s,a)的值最大，那它就是π′π′，即Qπ(s,π′(s))Qπ(s,π′(s))</li>
<li>直觀來看就是，在state-ss，用π(s)π(s)這個action來與環境互動，剩下的都用ππ與環境互動，其所得的reward會比沒有使用action-π′(s)π′(s)還要大。</li>
</ul>
</li>
</ul>
<p>將數學式展開：</p>
<ul>
<li>Vπ(s)≤Qπ(s,π′(s))Vπ(s)≤Qπ(s,π′(s))
<ul>
<li>=Eπ′[rt+1+Vπ(st+1)|st=s]=Eπ′[rt+1+Vπ(st+1)|st=s]
<ul>
<li>假設s=sts=st，QQ就等於rt+1+Vπ(st+1)rt+1+Vπ(st+1)</li>
</ul>
</li>
<li>≤Eπ′[rt+1+Qπ(st+1,π′(st+1))|st=s]≤Eπ′[rt+1+Qπ(st+1,π′(st+1))|st=s]
<ul>
<li>帶入上面推導出來的upper bound</li>
</ul>
</li>
<li>=Eπ′[rt+1+rt+2+Vπ(st+2)|st=s]=Eπ′[rt+1+rt+2+Vπ(st+2)|st=s]</li>
<li>≤Eπ′[rt+1+rt+2+Qπ(st+2,π′(st+2))|st=s]≤Eπ′[rt+1+rt+2+Qπ(st+2,π′(st+2))|st=s]</li>
<li>⋯≤Vπ′(s)⋯≤Vπ′(s)</li>
</ul>
</li>
</ul>
<p>假如給我們一個Actor-ππ，我們可以計算出它的Q-function，那我們就可以找到另外一個π′π′，它比原來的ππ還要更好。還要更好所指的就是Vπ(s)≤Vπ′(s)Vπ(s)≤Vπ′(s)。</p>
<h3 id="-23"><a href="#Estimate-Qpisa-by-TD" title="Estimate-Qpisa-by-TD"></a>Estimate Qπ(s,a)byTDQπ(s,a)byTD</h3>
<figure data-type="image" tabindex="22"><img src="https://i.imgur.com/A9hFcVI.png" alt="" loading="lazy"></figure>
<p>找QQ可以用MC，也可以用TD。</p>
<p>假設現在的序列為st,at,rt,st+1st,at,rt,st+1：</p>
<ul>
<li>我們可以計算出Qπ(st,at)Qπ(st,at)</li>
<li>只知道st+1st+1，但不知道機器會採取那一個action-at+1at+1，但我們可以預期機器會採取的action-π(st+1)π(st+1)</li>
<li>兩個時步中間會有一個差距，即rtrt</li>
<li>利用Gradient descent來求解
<ul>
<li>Qπ(st,at)Qπ(st,at)與rt+Qπ(st+1,π(st+1))rt+Qπ(st+1,π(st+1))愈接近愈好</li>
</ul>
</li>
</ul>
<p>實作上這兩個Q是相同的function，相同的參數，如果同時訓練會讓結果較不穩定，因此訓練的時候會將其中一個凍結，視為target，讓沒凍結的那個Q-function去擬合另一個已凍結的Q的Output，幾次迭代之後再將參數copy給另一個凍結的Q。</p>
<h3 id="-24"><a href="#Double-DQN" title="Double-DQN"></a>Double DQN</h3>
<figure data-type="image" tabindex="23"><img src="https://i.imgur.com/W7KvTzz.png" alt="" loading="lazy"></figure>
<p>實作Q-learning的時候很容易高估Q值，假設有四個action，其Q(st+1,a)Q(st+1,a)如下圖：<br>
<img src="https://i.imgur.com/1ZRBlZK.png" alt="" loading="lazy"></p>
<p>因為Q(st+1,a)Q(st+1,a)是估測出來的值，因此可能存在誤差，其誤差值有大有小，有正有負，而我們每次選擇都會選擇最大的那個：<br>
<img src="https://i.imgur.com/rO6DdUR.png" alt="" loading="lazy"></p>
<p>我們就發現到，當Q值有誤差的時候，我們通常都會選到高估的那個action，這時候訓練出來的結果也會是高估的。</p>
<h3 id="-25"><a href="#Double-DQN1" title="Double-DQN1"></a>Double DQN</h3>
<figure data-type="image" tabindex="24"><img src="https://i.imgur.com/y94N0dZ.png" alt="" loading="lazy"></figure>
<p><a href="https://papers.nips.cc/paper/3964-double-q-learning">論文連結_Double Q-learning</a><br>
<a href="https://arxiv.org/abs/1509.06461?context=cs">論文連結_Deep Reinforcement Learning with Double Q-learning</a><br>
對於這種高估的問題有一種處理技巧-Doule DQN，這個技巧需要兩個Q-function，QQ與Q′Q′：</p>
<ul>
<li>一個計算Q value(Q′Q′)，一個決定採取那一個action(QQ)
<ul>
<li>原始作法是用同一個Q-function來決定action，以及估測reward期望值</li>
</ul>
</li>
</ul>
<p>直觀來看，如果Q-value被高估，那代表QQ選出來的action是被估高的，但只要Q′Q′沒有高估QQ選出來的action就可以了。即使Q′Q′高估某一個action，但只要QQ沒有選到那個action就沒事了，兩者互相制衡。</p>
<h3 id="-26"><a href="#Dueling-DQN" title="Dueling-DQN"></a>Dueling DQN</h3>
<figure data-type="image" tabindex="25"><img src="https://i.imgur.com/HMVWP1g.png" alt="" loading="lazy"></figure>
<p><a href="http://proceedings.mlr.press/v48/wangf16.pdf">論文連結_Dueling Network Architectures for Deep Reinforcement Learning</a></p>
<p>Dueling是決鬥的意思，與原始DQN的差異僅在Output前：</p>
<ul>
<li>最後的Output之前會分叉會兩條路，其中一條只會Output一個value-V(s)V(s)，另一條會Output一個Vector-AA，其維度與最終輸出的action-aa一致，而A(s,a)+V(s)=Q(s,a)A(s,a)+V(s)=Q(s,a)。
<ul>
<li>論文中對於實作有另外的技巧避免V(s)=0V(s)=0，這部份有興趣的話可以直接閱讀論文。</li>
<li>A(s,a)A(s,a)：在state-ss採取action-aa，它比原來的Policy還要好多少。</li>
</ul>
</li>
</ul>
<p>Dueling DQN實作上比DQN的效果還要好，其中一點有趣的是它的可視化，它可以計算如何改變輸入(image)對V(s)V(s)以及A(s,a)A(s,a)的影響最大，這樣就可以看的出什麼樣的事情是與action有關，而什麼是無關的。</p>
<h3 id="-27"><a href="#Dueling-DQN---Visualization" title="Dueling-DQN---Visualization"></a>Dueling DQN - Visualization</h3>
<figure data-type="image" tabindex="26"><img src="https://i.imgur.com/Wo9Xmho.png" alt="" loading="lazy"></figure>
<p><a href="https://www.youtube.com/playlist?list=PLVFXyCSfS2Pau0gBh0mwTxDmutywWyFBP">論文影片連結</a></p>
<p>影片可以看的到，左邊會一直有紅色的閃光出來，這意味著這邊的pixel改變的時候對V(s)=0V(s)=0的影響最大。而右邊是顯示對A(s,a)A(s,a)(Advantage-function)影響最大的改變。</p>
<p>可以看的到，Advantage-function在車子出現在眼前的時候才會紅，因為車子靠近之後採取不同的action才會對結果有影響。但左邊的Value是每通過一輛車就會紅，它跟有沒有車有關，只要地平線的那端出現車子就會紅。</p>
<p>另一段打磚塊遊戲也是一樣的道理，左邊Value幾乎都有值，而接近下面的時候Advantage-function才會紅。</p>
<h3 id="-28"><a href="#Pathwise-Derivative-Policy-Gradient1" title="Pathwise-Derivative-Policy-Gradient1"></a>Pathwise Derivative Policy Gradient</h3>
<figure data-type="image" tabindex="27"><img src="https://i.imgur.com/8QmQkqk.png" alt="" loading="lazy"></figure>
<p>稍早的Q-learning中提到，只要有QQ，我們就找的到π′π′，不需要任何的actor。但如果現在我們有一個actor，而它的output就是我們要採取的action-aa，那是什麼情況?</p>
<p>假設我們有一個actor-ππ，input-ss，output-aa，然後要更新ππ為π′π′，而且我們希望Qπ(s,a)Qπ(s,a)的值愈大愈好。</p>
<p>實務上，如下圖所示，我們可以將整個串接起來視為一個較大的神經網路即可：<br>
<img src="https://i.imgur.com/mZkwFjv.png" alt="" loading="lazy"></p>
<p>當我們在更新actor的時候，就將QπQπ的參數固定住，再用Gradient Ascent來更新actor的參數：</p>
<ul>
<li>θπ′←θπ+η∇θπQπ(s,a)θπ′←θπ+η∇θπQπ(s,a)
<ul>
<li>計算θπθπ對Q-function的梯度再加上θπθπ得到θπ′θπ′</li>
</ul>
</li>
</ul>
<p>整個架構看起來跟GAN非常類似，但這種作法稱為Pathwise Derivative Policy Gradient</p>
<h3 id="-29"><a href="#Pathwise-Derivative-Policy-Gradient2" title="Pathwise-Derivative-Policy-Gradient2"></a>Pathwise Derivative Policy Gradient</h3>
<figure data-type="image" tabindex="28"><img src="https://i.imgur.com/DXy29Jb.png" alt="" loading="lazy"></figure>
<p>與Q-Learning一樣有三步驟，在估測Q-function的時候與一般的DQN是一樣的，不同的地方是在估測π′π′的部份。原始DQN中只需要有Q-function就夠，但在Pathwise Derivative Policy Gradient中是需要一個actor(<code>nn</code>)來得到action，然後透過調整actor的參數讓Q-function的Output愈大愈好。</p>
<p>這種情況下即使action是連續的也沒有關係，因為在testing的時候我們並不需要解一個argmaxargmax的問題，這部份是在training的時候處理掉了，testing的時候只需要input state就可以。</p>
<p>有一個通用的小技巧，就是Replay Buffer。意思是將過去與環境互動的所有資訊通通存下來放到一個Buffer內，訓練Q-function過程中再從這個Buffer中取值出來，並不單純只取ππ與環境互動的經驗，還會包含過去其它的actor與環境互動的經驗也都在裡面，這樣訓練過程會比較穩定。</p>
<p>另外一個小技巧，就是對actor的output加上noise，這可以幫助actor探索不同的環境。</p>
<h3 id="-30"><a href="#DDPG-Alogrithm" title="DDPG-Alogrithm"></a>DDPG Alogrithm</h3>
<figure data-type="image" tabindex="29"><img src="https://i.imgur.com/lACJ0W2.png" alt="" loading="lazy"></figure>
<p>DDPG=Deep Deterministic Policy Gradient</p>
<p>DDPG也是我們稍早所提到的Pathwise Derivative Policy Gradient的其中一種方式：</p>
<ul>
<li>有一個actor與critic，其初始化參數分別為critic-θQθQ與actor-θπθπ</li>
<li>有一個target critic-θQ′θQ′與有一個target actor-θπ′θπ′
<ul>
<li>這是估測Q-function的時候用的</li>
</ul>
</li>
<li>初始化一個replay buffer R</li>
<li>每次的迭代
<ul>
<li>用actor-ππ與環境互動，input-s，output-a，即π(s)π(s)，再針對Output加上noise，即π(s)π(s) + noise來幫助actor探索環境，並收集一堆訓練資料，將它們存放到Reply buffer-R。
<ul>
<li>訓練資料結構為{st,at,rt,st+1}{st,at,rt,st+1}</li>
</ul>
</li>
<li>從Reply buffer-R中sample出N筆資料</li>
<li>利用取出的N筆資料訓練critic-Q
<ul>
<li>調整Q的參數讓它與目標函數L=∑n(<sup>yn−Q(sn,an))2L=∑n(y</sup>n−Q(sn,an))2愈接近愈好
<ul>
<li>target-<sup>yn=rn+Q′(sn+1,π′(sn+1))y</sup>n=rn+Q′(sn+1,π′(sn+1))
<ul>
<li>以target actor-θπ′θπ′根據sn+1sn+1決定要採取什麼樣的action，得到Q′Q′之後加上rnrn</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>更新actor-ππ的參數，讓Q-function的值增加</li>
<li>更新target network
<ul>
<li>θπ′←mθπ+(1−m)θπ′θπ′←mθπ+(1−m)θπ′</li>
<li>θQ′←mθQ+(1−m)θQ′θQ′←mθQ+(1−m)θQ′</li>
<li>理論上可以直接讓θπ=θπ′,θQ′=θQθπ=θπ′,θQ′=θQ，但實務上我們會讓target networks乘上一個weight再與critic、actor做計算。
<ul>
<li>這麼做的好處是，target networks的變化會比較慢，訓練上也會比較穩定。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why am I doing iart.ai]]></title>
        <id>https://fuyunfei.github.io/post/wo-wei-he-yao-zuo-aiandart/</id>
        <link href="https://fuyunfei.github.io/post/wo-wei-he-yao-zuo-aiandart/">
        </link>
        <updated>2020-06-28T14:13:38.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>几千年来， 美和艺术服务于上帝，权贵，而所有人类对美和艺术的有着无限的需求，它们不应当被垄断。</li>
<li>我希望艺术和美的力量，在新的时代，无距离的打动每一个人。</li>
<li>我希望美和艺术可以更深入的触碰到每一个人， 无论贫富，地域，和年龄</li>
<li>我希望每一个个体可以无距离的接触美和艺术，无论贫富，地域，和年龄</li>
<li>我希望让大众生活的环境拥有更动人，更高级，更多样化的美和设计</li>
<li>我希望最大限度的解放艺术家和设计师的创造力和生产力。</li>
<li>我希望更广阔地去探索更多的未知的艺术和美的领域。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pytorch load part of the pretrained model]]></title>
        <id>https://fuyunfei.github.io/post/pytorch-jia-zai-xiang-tong-layer/</id>
        <link href="https://fuyunfei.github.io/post/pytorch-jia-zai-xiang-tong-layer/">
        </link>
        <updated>2020-05-21T15:07:57.000Z</updated>
        <content type="html"><![CDATA[<pre><code>pretrained_model = torch.load(args.resume)
pretrained_dict = pretrained_model['state_dict']

model_dict=model.state_dict()
# 1. filter out unnecessary keys
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}
# 2. overwrite entries in the existing state dict
model_dict.update(pretrained_dict)
model.load_state_dict(model_dict) 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CNN Tricks]]></title>
        <id>https://fuyunfei.github.io/post/cnn-trick-he-ji/</id>
        <link href="https://fuyunfei.github.io/post/cnn-trick-he-ji/">
        </link>
        <updated>2020-05-08T10:48:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="cnn-trick合集">cnn trick合集</h1>
<p>这两天发现了一篇宝藏paper，2019年CVPR中的一篇 <a href="https://link.zhihu.com/?target=http%3A//openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf">Bag of Tricks for Image Classification with Convolutional Neural Networks</a>。 这篇paper主要从3个方面讲述了提高现有baseline(ResNet-50)的有效trick：</p>
<ol>
<li>在新的硬件上有效训练</li>
<li>在ResNet-50的基础上，对模型进行了一些微量的调整</li>
<li>训练的一些技巧</li>
</ol>
<p>大概回顾这篇文章</p>
<h2 id="1-在新的硬件上有效训练">1. 在新的硬件上有效训练</h2>
<h3 id="11-背景">1.1 背景</h3>
<p>在ResNet刚提出的时候，为了考虑当时的硬件条件，不得不做很多跟performance相关的trade-offs。但是随着这几年硬件(尤其是GPU)的快速发展，很多与performance相关的trade-offs已经改变。其中包括：</p>
<ol>
<li>使用更大的batch size。例如从256到1024</li>
<li>使用较低的数值精度。例如从FP32到FP16</li>
</ol>
<h3 id="12-使用更大的batch-size">1.2 使用更大的batch size</h3>
<p>使用更大的batch size会导致减缓训练进度。对于凸问题，收敛速度会随着batch size的增加而降低。也就是说，在相同的epoch下，使用更大的batch size可能会导致验证集accuracy更低。因此使用一些trick来解决这个问题。</p>
<p><strong>Linear scaling learning rate</strong>：例如，当我们选择初始学习率为0.1，batch size为256时，那么当我们将batch size增大至b时，就需要将初始学习率增加曾0.1×b/256</p>
<p><strong>Learning rate warmup</strong>：例如，选择5个epoch去进行warmup，在这5个epoch中线性地从0开始增加学习率至初始学习率，然后再开始正常decay<br>
<strong>Zero</strong> <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-5032a1932221fb26d4520cdc5b09ad46.svg" alt="[公式]" loading="lazy"></p>
<p><strong>No bias decay</strong>：为了避免过拟合，对于权重weight和偏差bias，我们通常会使用weight decay。但在这里，仅对weight使用decay，而不对bias使用decay。</p>
<h3 id="13-使用更低的数值精度">1.3 使用更低的数值精度</h3>
<p>以前神经网络通常使用32-bit浮点数精度(FP32)来训练。但是现在的新的硬件增强了低精度数据类型的算术逻辑单元。例如Nvidia V100对FP32提供14 TFLOPS，而对FP16提供100 TFLOPS。因此，使用FP16时，总的训练速度加速了2~3倍：</p>
<figure data-type="image" tabindex="1"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-29cdfa738a5f43e1450ede322f297e72.jpg" alt="" loading="lazy"></figure>
<p>Comparison of the training time and validation accuracy for ResNet-50 between the baseline (BS=256 with FP32) and a more hardware efficient setting (BS=1024 with FP16).</p>
<figure data-type="image" tabindex="2"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a179819131ee35eb8e7adc45e25e16d6.jpg" alt="" loading="lazy"></figure>
<p>The breakdown effect for each effective training heuristic on ResNet-50.</p>
<h2 id="2-模型调整">2. 模型调整</h2>
<figure data-type="image" tabindex="3"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-96246a2fef83b606b8d755e766807144.jpg" alt="" loading="lazy"></figure>
<p>The architecture of ResNet-50. The convolution kernel size, output channel size and stride size (default is 1) are illustrated, similar for pooling layers.</p>
<p>主要对downsampling block和input steam(上图指出部分)做了一些改动：</p>
<ol>
<li>downsampling做改动主要是由于使用stride=2的1×1 conv会忽略3/4的feature-map。因此，为了使输出的shape保持不变，将path A的前两个conv分别改为stride=1的1×1 conv和stride=2的3×3 conv，即ResNet-C；将path B换成stride=2的2×2 AvgPool和stride=1的1×1 conv，即ResNet-D</li>
<li>而input steam做的改动主要是由于使用7×7 conv的计算cost是3×3的5.4倍。因此将7×7 conv换成3个连续的3×3conv，即ResNet-C</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a678db384db2fb0859cafc51ab31df20.jpg" alt="" loading="lazy"></figure>
<p>Three ResNet tweaks. ResNet-B modifies the downsampling block of Resnet. ResNet-C further modifies the input stem. On top of that, ResNet-D again modifies the downsampling block.</p>
<figure data-type="image" tabindex="5"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-f03f481d9e3ab12a3670fa759a767b1c.jpg" alt="" loading="lazy"></figure>
<p>Compare ResNet-50 with three model tweaks onmodel size, FLOPs and ImageNet validation accuracy.</p>
<h2 id="3-训练技巧">3. 训练技巧</h2>
<h3 id="31-cosine-learning-rate-decay">3.1 Cosine Learning Rate Decay</h3>
<p>以往学习率衰减的策略一般是&quot;step decay&quot;，即每隔一定的epoch，学习率才进行一次指数衰减。而现在，学习率随着epoch的增大不断衰减：</p>
<figure data-type="image" tabindex="6"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-39377e91419ac0e55e9f5fad8570f2a4.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-80683b364dc1edad22061c0883431c06.jpg" alt="" loading="lazy"></figure>
<p>Visualization of learning rate schedules with warm-up. Top: cosine and step schedules for batch size 1024. Bottom: Top-1 validation accuracy curve with regard to the two schedules.</p>
<h3 id="32-label-smoothing">3.2 Label Smoothing</h3>
<h3 id="33-knowledge-distillation">3.3 Knowledge Distillation</h3>
<h3 id="34-mixup-training">3.4 Mixup Training</h3>
<p>在mixup中，每次随机采样两个样本 <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-6f04414ac44928f5243849659cd507d4.svg" alt="[公式]" loading="lazy"> ，然后通过加权线性插值生成新的样本进行训练：</p>
<figure data-type="image" tabindex="8"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a38939c6e2718364bc3bb773974e7627.jpg" alt="" loading="lazy"></figure>
<p>其中 <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-11c2aab6fa911338924d499f8c391345.svg" alt="[公式]" loading="lazy"> 分布的得到的随机数。</p>
<h3 id="35-experiment-results">3.5 Experiment Results</h3>
<figure data-type="image" tabindex="9"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-f1595e29466f5dd2c058c840b29adf32.jpg" alt="" loading="lazy"></figure>
<p>The validation accuracies on ImageNet for stacking training refinements one by one. We repeat each refinement on ResNet-50-D for 4 times with different initialization, and report the mean and standard deviation in the table.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effective TensorFlow]]></title>
        <id>https://fuyunfei.github.io/post/effective-tensorflow/</id>
        <link href="https://fuyunfei.github.io/post/effective-tensorflow/">
        </link>
        <updated>2020-05-05T05:28:22.000Z</updated>
        <summary type="html"><![CDATA[<p>cc@https://github.com/vahidk/EffectiveTensorflow</p>
]]></summary>
        <content type="html"><![CDATA[<p>cc@https://github.com/vahidk/EffectiveTensorflow</p>
<!-- more -->
<h1 id="table-of-contents">Table of Contents</h1>
<h2 id="part-i-tensorflow-fundamentals">Part I: TensorFlow Fundamentals</h2>
<ol>
<li><a href="#basics">TensorFlow Basics</a></li>
<li><a href="#shapes">Understanding static and dynamic shapes</a></li>
<li><a href="#scopes">Scopes and when to use them</a></li>
<li><a href="#broadcast">Broadcasting the good and the ugly</a></li>
<li><a href="#data">Feeding data to TensorFlow</a></li>
<li><a href="#overloaded_ops">Take advantage of the overloaded operators</a></li>
<li><a href="#control_deps">Understanding order of execution and control dependencies</a></li>
<li><a href="#control_flow">Control flow operations: conditionals and loops</a></li>
<li><a href="#python_ops">Prototyping kernels and advanced visualization with Python ops</a></li>
<li><a href="#multi_gpu">Multi-GPU processing with data parallelism</a></li>
<li><a href="#debug">Debugging TensorFlow models</a></li>
<li><a href="#stable">Numerical stability in TensorFlow</a></li>
<li><a href="#tf_learn">Building a neural network training framework with learn API</a></li>
</ol>
<h2 id="part-ii-tensorflow-cookbook">Part II: TensorFlow Cookbook</h2>
<ol>
<li><a href="#get_shape">Get shape</a></li>
<li><a href="#batch_gather">Batch gather</a></li>
<li><a href="#beam_search">Beam search</a></li>
<li><a href="#merge">Merge</a></li>
<li><a href="#entropy">Entropy</a></li>
<li><a href="#kld">KL-Divergence</a></li>
<li><a href="#make_parallel">Make parallel</a></li>
<li><a href="#leaky_relu">Leaky Relu</a></li>
<li><a href="#batch_norm">Batch normalization</a></li>
</ol>
<hr>
<p><em>We updated the guide to follow the newly released TensorFlow 2.x API. Click <a href="https://github.com/vahidk/EffectiveTensorflow/tree/v1">here for v1 branch</a>, and <a href="https://github.com/vahidk/EffectiveTensorflow/tree/v2">here for v2 branch</a>.</em></p>
<p><em>We aim to gradually expand this series by adding new articles and keep the content up to date with the latest releases of TensorFlow API. If you have suggestions on how to improve this series or find the explanations ambiguous, feel free to create an issue, send patches, or reach out by email.</em></p>
<p><em>We encourage you to also check out the accompanied neural network training framework built on top of tf.estimator API. The <a href="https://github.com/vahidk/TensorflowFramework">framework</a> can be downloaded separately:</em></p>
<pre><code>git clone https://github.com/vahidk/TensorflowFramework.git
</code></pre>
<h1 id="part-i-tensorflow-fundamentals-2">Part I: TensorFlow Fundamentals</h1>
<p><a name="fundamentals"></a></p>
<h2 id="tensorflow-basics">TensorFlow Basics</h2>
<p><a name="basics"></a><br>
The most striking difference between TensorFlow and other numerical computation libraries such as NumPy is that operations in TensorFlow are symbolic. This is a powerful concept that allows TensorFlow to do all sort of things (e.g. automatic differentiation) that are not possible with imperative libraries such as NumPy. But it also comes at the cost of making it harder to grasp. Our attempt here is to demystify TensorFlow and provide some guidelines and best practices for more effective use of TensorFlow.</p>
<p>Let's start with a simple example, we want to multiply two random matrices. First we look at an implementation done in NumPy:</p>
<pre><code class="language-python">import numpy as np

x = np.random.normal(size=[10, 10])
y = np.random.normal(size=[10, 10])
z = np.dot(x, y)

print(z)
</code></pre>
<p>Now we perform the exact same computation this time in TensorFlow:</p>
<pre><code class="language-python">import tensorflow as tf

x = tf.random_normal([10, 10])
y = tf.random_normal([10, 10])
z = tf.matmul(x, y)

sess = tf.Session()
z_val = sess.run(z)

print(z_val)
</code></pre>
<p>Unlike NumPy that immediately performs the computation and produces the result, tensorflow only gives us a handle (of type Tensor) to a node in the graph that represents the result. If we try printing the value of z directly, we get something like this:</p>
<pre><code>Tensor(&quot;MatMul:0&quot;, shape=(10, 10), dtype=float32)
</code></pre>
<p>Since both the inputs have a fully defined shape, tensorflow is able to infer the shape of the tensor as well as its type. In order to compute the value of the tensor we need to create a session and evaluate it using Session.run() method.</p>
<hr>
<p><strong>Tip</strong>: When using Jupyter notebook make sure to call tf.reset_default_graph() at the beginning to clear the symbolic graph before defining new nodes.</p>
<hr>
<p>To understand how powerful symbolic computation can be let's have a look at another example. Assume that we have samples from a curve (say f(x) = 5x^2 + 3) and we want to estimate f(x) based on these samples. We define a parametric function g(x, w) = w0 x^2 + w1 x + w2, which is a function of the input x and latent parameters w, our goal is then to find the latent parameters such that g(x, w) ≈ f(x). This can be done by minimizing the following loss function: L(w) = ∑ (f(x) - g(x, w))^2. Although there's a closed form solution for this simple problem, we opt to use a more general approach that can be applied to any arbitrary differentiable function, and that is using stochastic gradient descent. We simply compute the average gradient of L(w) with respect to w over a set of sample points and move in the opposite direction.</p>
<p>Here's how it can be done in TensorFlow:</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf

# Placeholders are used to feed values from python to TensorFlow ops. We define
# two placeholders, one for input feature x, and one for output y.
x = tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)

# Assuming we know that the desired function is a polynomial of 2nd degree, we
# allocate a vector of size 3 to hold the coefficients. The variable will be
# automatically initialized with random noise.
w = tf.get_variable(&quot;w&quot;, shape=[3, 1])

# We define yhat to be our estimate of y.
f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)
yhat = tf.squeeze(tf.matmul(f, w), 1)

# The loss is defined to be the l2 distance between our estimate of y and its
# true value. We also added a shrinkage term, to ensure the resulting weights
# would be small.
loss = tf.nn.l2_loss(yhat - y) + 0.1 * tf.nn.l2_loss(w)

# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.
train_op = tf.train.AdamOptimizer(0.1).minimize(loss)

def generate_data():
    x_val = np.random.uniform(-10.0, 10.0, size=100)
    y_val = 5 * np.square(x_val) + 3
    return x_val, y_val

sess = tf.Session()
# Since we are using variables we first need to initialize them.
sess.run(tf.global_variables_initializer())
for _ in range(1000):
    x_val, y_val = generate_data()
    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})
    print(loss_val)
print(sess.run([w]))
</code></pre>
<p>By running this piece of code you should see a result close to this:</p>
<pre><code>[4.9924135, 0.00040895029, 3.4504161]
</code></pre>
<p>Which is a relatively close approximation to our parameters.</p>
<p>This is just tip of the iceberg for what TensorFlow can do. Many problems such as optimizing large neural networks with millions of parameters can be implemented efficiently in TensorFlow in just a few lines of code. TensorFlow takes care of scaling across multiple devices, and threads, and supports a variety of platforms.</p>
<h2 id="understanding-static-and-dynamic-shapes">Understanding static and dynamic shapes</h2>
<p><a name="shapes"></a><br>
Tensors in TensorFlow have a static shape attribute which is determined during graph construction. The static shape may be underspecified. For example we might define a tensor of shape [None, 128]:</p>
<pre><code class="language-python">import tensorflow as tf

a = tf.placeholder(tf.float32, [None, 128])
</code></pre>
<p>This means that the first dimension can be of any size and will be determined dynamically during Session.run(). You can query the static shape of a Tensor as follows:</p>
<pre><code class="language-python">static_shape = a.shape.as_list()  # returns [None, 128]
</code></pre>
<p>To get the dynamic shape of the tensor you can call tf.shape op, which returns a tensor representing the shape of the given tensor:</p>
<pre><code class="language-python">dynamic_shape = tf.shape(a)
</code></pre>
<p>The static shape of a tensor can be set with Tensor.set_shape() method:</p>
<pre><code class="language-python">a.set_shape([32, 128])  # static shape of a is [32, 128]
a.set_shape([None, 128])  # first dimension of a is determined dynamically
</code></pre>
<p>You can reshape a given tensor dynamically using tf.reshape function:</p>
<pre><code class="language-python">a =  tf.reshape(a, [32, 128])
</code></pre>
<p>It can be convenient to have a function that returns the static shape when available and dynamic shape when it's not. The following utility function does just that:</p>
<pre><code class="language-python">def get_shape(tensor):
  static_shape = tensor.shape.as_list()
  dynamic_shape = tf.unstack(tf.shape(tensor))
  dims = [s[1] if s[0] is None else s[0]
          for s in zip(static_shape, dynamic_shape)]
  return dims
</code></pre>
<p>Now imagine we want to convert a Tensor of rank 3 to a tensor of rank 2 by collapsing the second and third dimensions into one. We can use our get_shape() function to do that:</p>
<pre><code class="language-python">b = tf.placeholder(tf.float32, [None, 10, 32])
shape = get_shape(b)
b = tf.reshape(b, [shape[0], shape[1] * shape[2]])
</code></pre>
<p>Note that this works whether the shapes are statically specified or not.</p>
<p>In fact we can write a general purpose reshape function to collapse any list of dimensions:</p>
<pre><code class="language-python">import tensorflow as tf
import numpy as np

def reshape(tensor, dims_list):
  shape = get_shape(tensor)
  dims_prod = []
  for dims in dims_list:
    if isinstance(dims, int):
      dims_prod.append(shape[dims])
    elif all([isinstance(shape[d], int) for d in dims]):
      dims_prod.append(np.prod([shape[d] for d in dims]))
    else:
      dims_prod.append(tf.reduce_prod([shape[d] for d in dims]))
  tensor = tf.reshape(tensor, dims_prod)
  return tensor
</code></pre>
<p>Then collapsing the second dimension becomes very easy:</p>
<pre><code class="language-python">b = tf.placeholder(tf.float32, [None, 10, 32])
b = reshape(b, [0, [1, 2]])
</code></pre>
<h2 id="scopes-and-when-to-use-them">Scopes and when to use them</h2>
<p><a name="scopes"></a></p>
<p>Variables and tensors in TensorFlow have a name attribute that is used to identify them in the symbolic graph. If you don't specify a name when creating a variable or a tensor, TensorFlow automatically assigns a name for you:</p>
<pre><code class="language-python">a = tf.constant(1)
print(a.name)  # prints &quot;Const:0&quot;

b = tf.Variable(1)
print(b.name)  # prints &quot;Variable:0&quot;
</code></pre>
<p>You can overwrite the default name by explicitly specifying it:</p>
<pre><code class="language-python">a = tf.constant(1, name=&quot;a&quot;)
print(a.name)  # prints &quot;a:0&quot;

b = tf.Variable(1, name=&quot;b&quot;)
print(b.name)  # prints &quot;b:0&quot;
</code></pre>
<p>TensorFlow introduces two different context managers to alter the name of tensors and variables. The first is tf.name_scope:</p>
<pre><code class="language-python">with tf.name_scope(&quot;scope&quot;):
  a = tf.constant(1, name=&quot;a&quot;)
  print(a.name)  # prints &quot;scope/a:0&quot;

  b = tf.Variable(1, name=&quot;b&quot;)
  print(b.name)  # prints &quot;scope/b:0&quot;

  c = tf.get_variable(name=&quot;c&quot;, shape=[])
  print(c.name)  # prints &quot;c:0&quot;
</code></pre>
<p>Note that there are two ways to define new variables in TensorFlow, by creating a tf.Variable object or by calling tf.get_variable. Calling tf.get_variable with a new name results in creating a new variable, but if a variable with the same name exists it will raise a ValueError exception, telling us that re-declaring a variable is not allowed.</p>
<p>tf.name_scope affects the name of tensors and variables created with tf.Variable, but doesn't impact the variables created with tf.get_variable.</p>
<p>Unlike tf.name_scope, tf.variable_scope modifies the name of variables created with tf.get_variable as well:</p>
<pre><code class="language-python">with tf.variable_scope(&quot;scope&quot;):
  a = tf.constant(1, name=&quot;a&quot;)
  print(a.name)  # prints &quot;scope/a:0&quot;

  b = tf.Variable(1, name=&quot;b&quot;)
  print(b.name)  # prints &quot;scope/b:0&quot;

  c = tf.get_variable(name=&quot;c&quot;, shape=[])
  print(c.name)  # prints &quot;scope/c:0&quot;
</code></pre>
<pre><code class="language-python">with tf.variable_scope(&quot;scope&quot;):
  a1 = tf.get_variable(name=&quot;a&quot;, shape=[])
  a2 = tf.get_variable(name=&quot;a&quot;, shape=[])  # Disallowed
</code></pre>
<p>But what if we actually want to reuse a previously declared variable? Variable scopes also provide the functionality to do that:</p>
<pre><code class="language-python">with tf.variable_scope(&quot;scope&quot;):
  a1 = tf.get_variable(name=&quot;a&quot;, shape=[])
with tf.variable_scope(&quot;scope&quot;, reuse=True):
  a2 = tf.get_variable(name=&quot;a&quot;, shape=[])  # OK
</code></pre>
<p>This becomes handy for example when using built-in neural network layers:</p>
<pre><code class="language-python">with tf.variable_scope('my_scope'):
  features1 = tf.layers.conv2d(image1, filters=32, kernel_size=3)
# Use the same convolution weights to process the second image:
with tf.variable_scope('my_scope', reuse=True):
  features2 = tf.layers.conv2d(image2, filters=32, kernel_size=3)
</code></pre>
<p>Alternatively you can set reuse to tf.AUTO_REUSE which tells TensorFlow to create a new variable if a variable with the same name doesn't exist, and reuse otherwise:</p>
<pre><code class="language-python">with tf.variable_scope(&quot;scope&quot;, reuse=tf.AUTO_REUSE):
  features1 = tf.layers.conv2d(image1, filters=32, kernel_size=3)
  
with tf.variable_scope(&quot;scope&quot;, reuse=tf.AUTO_REUSE):
  features2 = tf.layers.conv2d(image2, filters=32, kernel_size=3)
</code></pre>
<p>If you want to do lots of variable sharing keeping track of when to define new variables and when to reuse them can be cumbersome and error prone. tf.AUTO_REUSE simplifies this task but adds the risk of sharing variables that weren't supposed to be shared. TensorFlow templates are another way of tackling the same problem without this risk:</p>
<pre><code class="language-python">conv3x32 = tf.make_template(&quot;conv3x32&quot;, lambda x: tf.layers.conv2d(x, 32, 3))
features1 = conv3x32(image1)
features2 = conv3x32(image2)  # Will reuse the convolution weights.
</code></pre>
<p>You can turn any function to a TensorFlow template. Upon the first call to a template, the variables defined inside the function would be declared and in the consecutive invocations they would automatically get reused.</p>
<h2 id="broadcasting-the-good-and-the-ugly">Broadcasting the good and the ugly</h2>
<p><a name="broadcast"></a><br>
TensorFlow supports broadcasting elementwise operations. Normally when you want to perform operations like addition and multiplication, you need to make sure that shapes of the operands match, e.g. you can’t add a tensor of shape [3, 2] to a tensor of shape [3, 4]. But there’s a special case and that’s when you have a singular dimension. TensorFlow implicitly tiles the tensor across its singular dimensions to match the shape of the other operand. So it’s valid to add a tensor of shape [3, 2] to a tensor of shape [3, 1]</p>
<pre><code class="language-python">import tensorflow as tf

a = tf.constant([[1., 2.], [3., 4.]])
b = tf.constant([[1.], [2.]])
# c = a + tf.tile(b, [1, 2])
c = a + b
</code></pre>
<p>Broadcasting allows us to perform implicit tiling which makes the code shorter, and more memory efficient, since we don’t need to store the result of the tiling operation. One neat place that this can be used is when combining features of varying length. In order to concatenate features of varying length we commonly tile the input tensors, concatenate the result and apply some nonlinearity. This is a common pattern across a variety of neural network architectures:</p>
<pre><code class="language-python">a = tf.random_uniform([5, 3, 5])
b = tf.random_uniform([5, 1, 6])

# concat a and b and apply nonlinearity
tiled_b = tf.tile(b, [1, 3, 1])
c = tf.concat([a, tiled_b], 2)
d = tf.layers.dense(c, 10, activation=tf.nn.relu)
</code></pre>
<p>But this can be done more efficiently with broadcasting. We use the fact that f(m(x + y)) is equal to f(mx + my). So we can do the linear operations separately and use broadcasting to do implicit concatenation:</p>
<pre><code class="language-python">pa = tf.layers.dense(a, 10)
pb = tf.layers.dense(b, 10)
d = tf.nn.relu(pa + pb)
</code></pre>
<p>In fact this piece of code is pretty general and can be applied to tensors of arbitrary shape as long as broadcasting between tensors is possible:</p>
<pre><code class="language-python">def merge(a, b, units, activation=tf.nn.relu):
    pa = tf.layers.dense(a, units)
    pb = tf.layers.dense(b, units)
    c = pa + pb
    if activation is not None:
        c = activation(c)
    return c
</code></pre>
<p>A slightly more general form of this function is <a href="#merge">included</a> in the cookbook.</p>
<p>So far we discussed the good part of broadcasting. But what’s the ugly part you may ask? Implicit assumptions almost always make debugging harder to do. Consider the following example:</p>
<pre><code class="language-python">a = tf.constant([[1.], [2.]])
b = tf.constant([1., 2.])
c = tf.reduce_sum(a + b)
</code></pre>
<p>What do you think the value of c would be after evaluation? If you guessed 6, that’s wrong. It’s going to be 12. This is because when rank of two tensors don’t match, TensorFlow automatically expands the first dimension of the tensor with lower rank before the elementwise operation, so the result of addition would be [[2, 3], [3, 4]], and the reducing over all parameters would give us 12.</p>
<p>The way to avoid this problem is to be as explicit as possible. Had we specified which dimension we would want to reduce across, catching this bug would have been much easier:</p>
<pre><code class="language-python">a = tf.constant([[1.], [2.]])
b = tf.constant([1., 2.])
c = tf.reduce_sum(a + b, 0)
</code></pre>
<p>Here the value of c would be [5, 7], and we immediately would guess based on the shape of the result that there’s something wrong. A general rule of thumb is to always specify the dimensions in reduction operations and when using tf.squeeze.</p>
<h2 id="feeding-data-to-tensorflow">Feeding data to TensorFlow</h2>
<p><a name="data"></a></p>
<p>TensorFlow is designed to work efficiently with large amount of data. So it's important not to starve your TensorFlow model in order to maximize its performance. There are various ways that you can feed your data to TensorFlow.</p>
<h3 id="constants">Constants</h3>
<p>The simplest approach is to embed the data in your graph as a constant:</p>
<pre><code class="language-python">import tensorflow as tf
import numpy as np

actual_data = np.random.normal(size=[100])

data = tf.constant(actual_data)
</code></pre>
<p>This approach can be very efficient, but it's not very flexible. One problem with this approach is that, in order to use your model with another dataset you have to rewrite the graph. Also, you have to load all of your data at once and keep it in memory which would only work with small datasets.</p>
<h3 id="placeholders">Placeholders</h3>
<p>Using placeholders solves both of these problems:</p>
<pre><code class="language-python">import tensorflow as tf
import numpy as np

data = tf.placeholder(tf.float32)

prediction = tf.square(data) + 1

actual_data = np.random.normal(size=[100])

tf.Session().run(prediction, feed_dict={data: actual_data})
</code></pre>
<p>Placeholder operator returns a tensor whose value is fetched through the feed_dict argument in Session.run function. Note that running Session.run without feeding the value of data in this case will result in an error.</p>
<h3 id="python-ops">Python ops</h3>
<p>Another approach to feed the data to TensorFlow is by using Python ops:</p>
<pre><code class="language-python">def py_input_fn():
    actual_data = np.random.normal(size=[100])
    return actual_data

data = tf.py_func(py_input_fn, [], (tf.float32))
</code></pre>
<p>Python ops allow you to convert a regular Python function to a TensorFlow operation.</p>
<h3 id="dataset-api">Dataset API</h3>
<p>The recommended way of reading the data in TensorFlow however is through the dataset API:</p>
<pre><code class="language-python">actual_data = np.random.normal(size=[100])
dataset = tf.data.Dataset.from_tensor_slices(actual_data)
data = dataset.make_one_shot_iterator().get_next()
</code></pre>
<p>If you need to read your data from file, it may be more efficient to write it in TFrecord format and use TFRecordDataset to read it:</p>
<pre><code class="language-python">dataset = tf.data.TFRecordDataset(path_to_data)
</code></pre>
<p>See the <a href="https://www.tensorflow.org/api_guides/python/reading_data#Reading_from_files">official docs</a> for an example of how to write your dataset in TFrecord format.</p>
<p>Dataset API allows you to make efficient data processing pipelines easily. For example this is how we process our data in the accompanied framework (See<br>
<a href="https://github.com/vahidk/TensorflowFramework/blob/master/trainer.py">trainer.py</a>):</p>
<pre><code class="language-python">dataset = ...
dataset = dataset.cache()
if mode == tf.estimator.ModeKeys.TRAIN:
    dataset = dataset.repeat()
    dataset = dataset.shuffle(batch_size * 5)
dataset = dataset.map(parse, num_threads=8)
dataset = dataset.batch(batch_size)
</code></pre>
<p>After reading the data, we use Dataset.cache method to cache it into memory for improved efficiency. During the training mode, we repeat the dataset indefinitely. This allows us to process the whole dataset many times. We also shuffle the dataset to get batches with different sample distributions. Next, we use the Dataset.map function to perform preprocessing on raw records and convert the data to a usable format for the model. We then create batches of samples by calling Dataset.batch.</p>
<h2 id="take-advantage-of-the-overloaded-operators">Take advantage of the overloaded operators</h2>
<p><a name="overloaded_ops"></a><br>
Just like NumPy, TensorFlow overloads a number of python operators to make building graphs easier and the code more readable.</p>
<p>The slicing op is one of the overloaded operators that can make indexing tensors very easy:</p>
<pre><code class="language-python">z = x[begin:end]  # z = tf.slice(x, [begin], [end-begin])
</code></pre>
<p>Be very careful when using this op though. The slicing op is very inefficient and often better avoided, especially when the number of slices is high. To understand how inefficient this op can be let's look at an example. We want to manually perform reduction across the rows of a matrix:</p>
<pre><code class="language-python">import tensorflow as tf
import time

x = tf.random_uniform([500, 10])

z = tf.zeros([10])
for i in range(500):
    z += x[i]

sess = tf.Session()
start = time.time()
sess.run(z)
print(&quot;Took %f seconds.&quot; % (time.time() - start))
</code></pre>
<p>On my MacBook Pro, this took 2.67 seconds to run! The reason is that we are calling the slice op 500 times, which is going to be very slow to run. A better choice would have been to use tf.unstack op to slice the matrix into a list of vectors all at once:</p>
<pre><code class="language-python">z = tf.zeros([10])
for x_i in tf.unstack(x):
    z += x_i
</code></pre>
<p>This took 0.18 seconds. Of course, the right way to do this simple reduction is to use tf.reduce_sum op:</p>
<pre><code class="language-python">z = tf.reduce_sum(x, axis=0)
</code></pre>
<p>This took 0.008 seconds, which is 300x faster than the original implementation.</p>
<p>TensorFlow also overloads a range of arithmetic and logical operators:</p>
<pre><code class="language-python">z = -x  # z = tf.negative(x)
z = x + y  # z = tf.add(x, y)
z = x - y  # z = tf.subtract(x, y)
z = x * y  # z = tf.mul(x, y)
z = x / y  # z = tf.div(x, y)
z = x // y  # z = tf.floordiv(x, y)
z = x % y  # z = tf.mod(x, y)
z = x ** y  # z = tf.pow(x, y)
z = x @ y  # z = tf.matmul(x, y)
z = x &gt; y  # z = tf.greater(x, y)
z = x &gt;= y  # z = tf.greater_equal(x, y)
z = x &lt; y  # z = tf.less(x, y)
z = x &lt;= y  # z = tf.less_equal(x, y)
z = abs(x)  # z = tf.abs(x)
z = x &amp; y  # z = tf.logical_and(x, y)
z = x | y  # z = tf.logical_or(x, y)
z = x ^ y  # z = tf.logical_xor(x, y)
z = ~x  # z = tf.logical_not(x)
</code></pre>
<p>You can also use the augmented version of these ops. For example <code>x += y</code> and <code>x **= 2</code> are also valid.</p>
<p>Note that Python doesn't allow overloading &quot;and&quot;, &quot;or&quot;, and &quot;not&quot; keywords.</p>
<p>TensorFlow also doesn't allow using tensors as booleans, as it may be error prone:</p>
<pre><code class="language-python">x = tf.constant(1.)
if x:  # This will raise a TypeError error
    ...
</code></pre>
<p>You can either use tf.cond(x, ...) if you want to check the value of the tensor, or use &quot;if x is None&quot; to check the value of the variable.</p>
<p>Other operators that aren't supported are equal (==) and not equal (!=) operators which are overloaded in NumPy but not in TensorFlow. Use the function versions instead which are <code>tf.equal</code> and <code>tf.not_equal</code>.</p>
<h2 id="understanding-order-of-execution-and-control-dependencies">Understanding order of execution and control dependencies</h2>
<p><a name="control_deps"></a><br>
As we discussed in the first item, TensorFlow doesn't immediately run the operations that are defined but rather creates corresponding nodes in a graph that can be evaluated with Session.run() method. This also enables TensorFlow to do optimizations at run time to determine the optimal order of execution and possible trimming of unused nodes. If you only have tf.Tensors in your graph you don't need to worry about dependencies but you most probably have tf.Variables too, and tf.Variables make things much more difficult. My advice to is to only use Variables if Tensors don't do the job. This might not make a lot of sense to you now, so let's start with an example.</p>
<pre><code class="language-python">import tensorflow as tf

a = tf.constant(1)
b = tf.constant(2)
a = a + b

tf.Session().run(a)
</code></pre>
<p>Evaluating &quot;a&quot; will return the value 3 as expected.  Note that here we are creating 3 tensors, two constant tensors and another tensor that stores the result of the addition. Note that you can't overwrite the value of a tensor. If you want to modify it you have to create a new tensor. As we did here.</p>
<hr>
<p><strong>TIP</strong>: If you don't define a new graph, TensorFlow automatically creates a graph for you by default. You can use tf.get_default_graph() to get a handle to the graph. You can then inspect the graph, for example by printing all its tensors:</p>
<pre><code class="language-python">print(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))
</code></pre>
<hr>
<p>Unlike tensors, variables can be updated. So let's see how we may use variables to do the same thing:</p>
<pre><code class="language-python">a = tf.Variable(1)
b = tf.constant(2)
assign = tf.assign(a, a + b)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
print(sess.run(assign))
</code></pre>
<p>Again, we get 3 as expected. Note that tf.assign returns a tensor representing the value of the assignment.<br>
So far everything seemed to be fine, but let's look at a slightly more complicated example:</p>
<pre><code class="language-python">a = tf.Variable(1)
b = tf.constant(2)
c = a + b

assign = tf.assign(a, 5)

sess = tf.Session()
for i in range(10):
    sess.run(tf.global_variables_initializer())
    print(sess.run([assign, c]))
</code></pre>
<p>Note that the tensor c here won't have a deterministic value. This value might be 3 or 7 depending on whether addition or assignment gets executed first.</p>
<p>You should note that the order that you define ops in your code doesn't matter to TensorFlow runtime. The only thing that matters is the control dependencies. Control dependencies for tensors are straightforward. Every time you use a tensor in an operation that op will define an implicit dependency to that tensor. But things get complicated with variables because they can take many values.</p>
<p>When dealing with variables, you may need to explicitly define dependencies using tf.control_dependencies() as follows:</p>
<pre><code class="language-python">a = tf.Variable(1)
b = tf.constant(2)
c = a + b

with tf.control_dependencies([c]):
    assign = tf.assign(a, 5)

sess = tf.Session()
for i in range(10):
    sess.run(tf.global_variables_initializer())
    print(sess.run([assign, c]))
</code></pre>
<p>This will make sure that the assign op will be called after the addition.</p>
<h2 id="control-flow-operations-conditionals-and-loops">Control flow operations: conditionals and loops</h2>
<p><a name="control_flow"></a><br>
When building complex models such as recurrent neural networks you may need to control the flow of operations through conditionals and loops. In this section we introduce a number of commonly used control flow ops.</p>
<p>Let's assume you want to decide whether to multiply to or add two given tensors based on a predicate. This can be simply implemented with tf.cond which acts as a python &quot;if&quot; function:</p>
<pre><code class="language-python">a = tf.constant(1)
b = tf.constant(2)

p = tf.constant(True)

x = tf.cond(p, lambda: a + b, lambda: a * b)

print(tf.Session().run(x))
</code></pre>
<p>Since the predicate is True in this case, the output would be the result of the addition, which is 3.</p>
<p>Most of the times when using TensorFlow you are using large tensors and want to perform operations in batch. A related conditional operation is tf.where, which like tf.cond takes a predicate, but selects the output based on the condition in batch.</p>
<pre><code class="language-python">a = tf.constant([1, 1])
b = tf.constant([2, 2])

p = tf.constant([True, False])

x = tf.where(p, a + b, a * b)

print(tf.Session().run(x))
</code></pre>
<p>This will return [3, 2].</p>
<p>Another widely used control flow operation is tf.while_loop. It allows building dynamic loops in TensorFlow that operate on sequences of variable length. Let's see how we can generate Fibonacci sequence with tf.while_loops:</p>
<pre><code class="language-python">n = tf.constant(5)

def cond(i, a, b):
    return i &lt; n

def body(i, a, b):
    return i + 1, b, a + b

i, a, b = tf.while_loop(cond, body, (2, 1, 1))

print(tf.Session().run(b))
</code></pre>
<p>This will print 5. tf.while_loops takes a condition function, and a loop body function, in addition to initial values for loop variables. These loop variables are then updated by multiple calls to the body function until the condition returns false.</p>
<p>Now imagine we want to keep the whole series of Fibonacci sequence. We may update our body to keep a record of the history of current values:</p>
<pre><code class="language-python">n = tf.constant(5)

def cond(i, a, b, c):
    return i &lt; n

def body(i, a, b, c):
    return i + 1, b, a + b, tf.concat([c, [a + b]], 0)

i, a, b, c = tf.while_loop(cond, body, (2, 1, 1, tf.constant([1, 1])))

print(tf.Session().run(c))
</code></pre>
<p>Now if you try running this, TensorFlow will complain that the shape of the the fourth loop variable is changing. So you must make that explicit that it's intentional:</p>
<pre><code>i, a, b, c = tf.while_loop(
    cond, body, (2, 1, 1, tf.constant([1, 1])),
    shape_invariants=(tf.TensorShape([]),
                      tf.TensorShape([]),
                      tf.TensorShape([]),
                      tf.TensorShape([None])))
</code></pre>
<p>This is not only getting ugly, but is also somewhat inefficient. Note that we are building a lot of intermediary tensors that we don't use. TensorFlow has a better solution for this kind of growing arrays. Meet tf.TensorArray. Let's do the same thing this time with tensor arrays:</p>
<pre><code class="language-python">n = tf.constant(5)

c = tf.TensorArray(tf.int32, n)
c = c.write(0, 1)
c = c.write(1, 1)

def cond(i, a, b, c):
    return i &lt; n

def body(i, a, b, c):
    c = c.write(i, a + b)
    return i + 1, b, a + b, c

i, a, b, c = tf.while_loop(cond, body, (2, 1, 1, c))

c = c.stack()

print(tf.Session().run(c))
</code></pre>
<p>TensorFlow while loops and tensor arrays are essential tools for building complex recurrent neural networks. As an exercise try implementing <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> using tf.while_loops. Can you make it more efficient with tensor arrays?</p>
<h2 id="prototyping-kernels-and-advanced-visualization-with-python-ops">Prototyping kernels and advanced visualization with Python ops</h2>
<p><a name="python_ops"></a><br>
Operation kernels in TensorFlow are entirely written in C++ for efficiency. But writing a TensorFlow kernel in C++ can be quite a pain. So, before spending hours implementing your kernel you may want to prototype something quickly, however inefficient. With tf.py_func() you can turn any piece of python code to a TensorFlow operation.</p>
<p>For example this is how you can implement a simple ReLU nonlinearity kernel in TensorFlow as a python op:</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf
import uuid

def relu(inputs):
    # Define the op in python
    def _relu(x):
        return np.maximum(x, 0.)

    # Define the op's gradient in python
    def _relu_grad(x):
        return np.float32(x &gt; 0)

    # An adapter that defines a gradient op compatible with TensorFlow
    def _relu_grad_op(op, grad):
        x = op.inputs[0]
        x_grad = grad * tf.py_func(_relu_grad, [x], tf.float32)
        return x_grad

    # Register the gradient with a unique id
    grad_name = &quot;MyReluGrad_&quot; + str(uuid.uuid4())
    tf.RegisterGradient(grad_name)(_relu_grad_op)

    # Override the gradient of the custom op
    g = tf.get_default_graph()
    with g.gradient_override_map({&quot;PyFunc&quot;: grad_name}):
        output = tf.py_func(_relu, [inputs], tf.float32)
    return output
</code></pre>
<p>To verify that the gradients are correct you can use TensorFlow's gradient checker:</p>
<pre><code class="language-python">x = tf.random_normal([10])
y = relu(x * x)

with tf.Session():
    diff = tf.test.compute_gradient_error(x, [10], y, [10])
    print(diff)
</code></pre>
<p>compute_gradient_error() computes the gradient numerically and returns the difference with the provided gradient. What we want is a very low difference.</p>
<p>Note that this implementation is pretty inefficient, and is only useful for prototyping, since the python code is not parallelizable and won't run on GPU. Once you verified your idea, you definitely would want to write it as a C++ kernel.</p>
<p>In practice we commonly use python ops to do visualization on Tensorboard. Consider the case that you are building an image classification model and want to visualize your model predictions during training. TensorFlow allows visualizing images with tf.summary.image() function:</p>
<pre><code class="language-python">image = tf.placeholder(tf.float32)
tf.summary.image(&quot;image&quot;, image)
</code></pre>
<p>But this only visualizes the input image. In order to visualize the predictions you have to find a way to add annotations to the image which may be almost impossible with existing ops. An easier way to do this is to do the drawing in python, and wrap it in a python op:</p>
<pre><code class="language-python">import io
import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf

def visualize_labeled_images(images, labels, max_outputs=3, name=&quot;image&quot;):
    def _visualize_image(image, label):
        # Do the actual drawing in python
        fig = plt.figure(figsize=(3, 3), dpi=80)
        ax = fig.add_subplot(111)
        ax.imshow(image[::-1,...])
        ax.text(0, 0, str(label),
          horizontalalignment=&quot;left&quot;,
          verticalalignment=&quot;top&quot;)
        fig.canvas.draw()

        # Write the plot as a memory file.
        buf = io.BytesIO()
        data = fig.savefig(buf, format=&quot;png&quot;)
        buf.seek(0)

        # Read the image and convert to numpy array
        img = PIL.Image.open(buf)
        return np.array(img.getdata()).reshape(img.size[0], img.size[1], -1)

    def _visualize_images(images, labels):
        # Only display the given number of examples in the batch
        outputs = []
        for i in range(max_outputs):
            output = _visualize_image(images[i], labels[i])
            outputs.append(output)
        return np.array(outputs, dtype=np.uint8)

    # Run the python op.
    figs = tf.py_func(_visualize_images, [images, labels], tf.uint8)
    return tf.summary.image(name, figs)
</code></pre>
<p>Note that since summaries are usually only evaluated once in a while (not per step), this implementation may be used in practice without worrying about efficiency.</p>
<h2 id="multi-gpu-processing-with-data-parallelism">Multi-GPU processing with data parallelism</h2>
<p><a name="multi_gpu"></a><br>
If you write your software in a language like C++ for a single cpu core, making it run on multiple GPUs in parallel would require rewriting the software from scratch. But this is not the case with TensorFlow. Because of its symbolic nature, tensorflow can hide all that complexity, making it effortless to scale your program across many CPUs and GPUs.</p>
<p>Let's start with the simple example of adding two vectors on CPU:</p>
<pre><code class="language-python">import tensorflow as tf

with tf.device(tf.DeviceSpec(device_type=&quot;CPU&quot;, device_index=0)):
   a = tf.random_uniform([1000, 100])
   b = tf.random_uniform([1000, 100])
   c = a + b

tf.Session().run(c)
</code></pre>
<p>The same thing can as simply be done on GPU:</p>
<pre><code class="language-python">with tf.device(tf.DeviceSpec(device_type=&quot;GPU&quot;, device_index=0)):
    a = tf.random_uniform([1000, 100])
    b = tf.random_uniform([1000, 100])
    c = a + b
</code></pre>
<p>But what if we have two GPUs and want to utilize both? To do that, we can split the data and use a separate GPU for processing each half:</p>
<pre><code class="language-python">split_a = tf.split(a, 2)
split_b = tf.split(b, 2)

split_c = []
for i in range(2):
    with tf.device(tf.DeviceSpec(device_type=&quot;GPU&quot;, device_index=i)):
        split_c.append(split_a[i] + split_b[i])

c = tf.concat(split_c, axis=0)
</code></pre>
<p>Let's rewrite this in a more general form so that we can replace addition with any other set of operations:</p>
<pre><code class="language-python">def make_parallel(fn, num_gpus, **kwargs):
    in_splits = {}
    for k, v in kwargs.items():
        in_splits[k] = tf.split(v, num_gpus)

    out_split = []
    for i in range(num_gpus):
        with tf.device(tf.DeviceSpec(device_type=&quot;GPU&quot;, device_index=i)):
            with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):
                out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))

    return tf.concat(out_split, axis=0)


def model(a, b):
    return a + b

c = make_parallel(model, 2, a=a, b=b)
</code></pre>
<p>You can replace the model with any function that takes a set of tensors as input and returns a tensor as result with the condition that both the input and output are in batch. Note that we also added a variable scope and set the reuse to true. This makes sure that we use the same variables for processing both splits. This is something that will become handy in our next example.</p>
<p>Let's look at a slightly more practical example. We want to train a neural network on multiple GPUs. During training we not only need to compute the forward pass but also need to compute the backward pass (the gradients). But how can we parallelize the gradient computation? This turns out to be pretty easy.</p>
<p>Recall from the first item that we wanted to fit a second degree polynomial to a set of samples. We reorganized the code a bit to have the bulk of the operations in the model function:</p>
<pre><code class="language-python">import numpy as np
import tensorflow as tf

def model(x, y):
    w = tf.get_variable(&quot;w&quot;, shape=[3, 1])

    f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)
    yhat = tf.squeeze(tf.matmul(f, w), 1)

    loss = tf.square(yhat - y)
    return loss

x = tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)

loss = model(x, y)

train_op = tf.train.AdamOptimizer(0.1).minimize(
    tf.reduce_mean(loss))

def generate_data():
    x_val = np.random.uniform(-10.0, 10.0, size=100)
    y_val = 5 * np.square(x_val) + 3
    return x_val, y_val

sess = tf.Session()
sess.run(tf.global_variables_initializer())
for _ in range(1000):
    x_val, y_val = generate_data()
    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})

_, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})
print(sess.run(tf.contrib.framework.get_variables_by_name(&quot;w&quot;)))
</code></pre>
<p>Now let's use make_parallel that we just wrote to parallelize this. We only need to change two lines of code from the above code:</p>
<pre><code class="language-python">loss = make_parallel(model, 2, x=x, y=y)

train_op = tf.train.AdamOptimizer(0.1).minimize(
    tf.reduce_mean(loss),
    colocate_gradients_with_ops=True)
</code></pre>
<p>The only thing that we need to change to parallelize backpropagation of gradients is to set the colocate_gradients_with_ops flag to true. This ensures that gradient ops run on the same device as the original op.</p>
<h2 id="debugging-tensorflow-models">Debugging TensorFlow models</h2>
<p><a name="debug"></a><br>
Symbolic nature of TensorFlow makes it relatively more difficult to debug TensorFlow code compared to regular python code. Here we introduce a number of tools included with TensorFlow that make debugging much easier.</p>
<p>Probably the most common error one can make when using TensorFlow is passing Tensors of wrong shape to ops. Many TensorFlow ops can operate on tensors of different ranks and shapes. This can be convenient when using the API, but may lead to extra headache when things go wrong.</p>
<p>For example, consider the tf.matmul op, it can multiply two matrices:</p>
<pre><code class="language-python">a = tf.random_uniform([2, 3])
b = tf.random_uniform([3, 4])
c = tf.matmul(a, b)  # c is a tensor of shape [2, 4]
</code></pre>
<p>But the same function also does batch matrix multiplication:</p>
<pre><code class="language-python">a = tf.random_uniform([10, 2, 3])
b = tf.random_uniform([10, 3, 4])
tf.matmul(a, b)  # c is a tensor of shape [10, 2, 4]
</code></pre>
<p>Another example that we talked about before in the <a href="#broadcast">broadcasting</a> section is add operation which supports broadcasting:</p>
<pre><code class="language-python">a = tf.constant([[1.], [2.]])
b = tf.constant([1., 2.])
c = a + b  # c is a tensor of shape [2, 2]
</code></pre>
<h3 id="validating-your-tensors-with-tfassert-ops">Validating your tensors with tf.assert* ops</h3>
<p>One way to reduce the chance of unwanted behavior is to explicitly verify the rank or shape of intermediate tensors with tf.assert* ops.</p>
<pre><code class="language-python">a = tf.constant([[1.], [2.]])
b = tf.constant([1., 2.])
check_a = tf.assert_rank(a, 1)  # This will raise an InvalidArgumentError exception
check_b = tf.assert_rank(b, 1)
with tf.control_dependencies([check_a, check_b]):
    c = a + b  # c is a tensor of shape [2, 2]
</code></pre>
<p>Remember that assertion nodes like other operations are part of the graph and if not evaluated would get pruned during Session.run(). So make sure to create explicit dependencies to assertion ops, to force TensorFlow to execute them.</p>
<p>You can also use assertions to validate the value of tensors at runtime:</p>
<pre><code class="language-python">check_pos = tf.assert_positive(a)
</code></pre>
<p>See the official docs for a <a href="https://www.tensorflow.org/api_guides/python/check_ops">full list of assertion ops</a>.</p>
<h3 id="logging-tensor-values-with-tfprint">Logging tensor values with tf.Print</h3>
<p>Another useful built-in function for debugging is tf.Print which logs the given tensors to the standard error:</p>
<pre><code class="language-python">input_copy = tf.Print(input, tensors_to_print_list)
</code></pre>
<p>Note that tf.Print returns a copy of its first argument as output. One way to force tf.Print to run is to pass its output to another op that gets executed. For example if we want to print the value of tensors a and b before adding them we could do something like this:</p>
<pre><code class="language-python">a = ...
b = ...
a = tf.Print(a, [a, b])
c = a + b
</code></pre>
<p>Alternatively we could manually define a control dependency.</p>
<h3 id="check-your-gradients-with-tfcompute_gradient_error">Check your gradients with tf.compute_gradient_error</h3>
<p><strong>Not</strong> all the operations in TensorFlow come with gradients, and it's easy to unintentionally build graphs for which TensorFlow can not compute the gradients.</p>
<p>Let's look at an example:</p>
<pre><code class="language-python">import tensorflow as tf

def non_differentiable_softmax_entropy(logits):
    probs = tf.nn.softmax(logits)
    return tf.nn.softmax_cross_entropy_with_logits(labels=probs, logits=logits)

w = tf.get_variable(&quot;w&quot;, shape=[5])
y = -non_differentiable_softmax_entropy(w)

opt = tf.train.AdamOptimizer()
train_op = opt.minimize(y)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
for i in range(10000):
    sess.run(train_op)

print(sess.run(tf.nn.softmax(w)))
</code></pre>
<p>We are using tf.nn.softmax_cross_entropy_with_logits to define entropy over a categorical distribution. We then use Adam optimizer to find the weights with maximum entropy. If you have passed a course on information theory, you would know that uniform distribution contains maximum entropy. So you would expect for the result to be [0.2, 0.2, 0.2, 0.2, 0.2]. But if you run this you may get unexpected results like this:</p>
<pre><code>[ 0.34081486  0.24287023  0.23465775  0.08935683  0.09230034]
</code></pre>
<p>It turns out tf.nn.softmax_cross_entropy_with_logits has undefined gradients with respect to labels! But how may we spot this if we didn't know?</p>
<p>Fortunately for us TensorFlow comes with a numerical differentiator that can be used to find symbolic gradient errors. Let's see how we can use it:</p>
<pre><code class="language-python">with tf.Session():
    diff = tf.test.compute_gradient_error(w, [5], y, [])
    print(diff)
</code></pre>
<p>If you run this, you would see that the difference between the numerical and symbolic gradients are pretty high (0.06 - 0.1 in my tries).</p>
<p>Now let's fix our function with a differentiable version of the entropy and check again:</p>
<pre><code class="language-python">import tensorflow as tf
import numpy as np

def softmax_entropy(logits, dim=-1):
    plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim)
    return -tf.reduce_sum(plogp, dim)

w = tf.get_variable(&quot;w&quot;, shape=[5])
y = -softmax_entropy(w)

print(w.get_shape())
print(y.get_shape())

with tf.Session() as sess:
    diff = tf.test.compute_gradient_error(w, [5], y, [])
    print(diff)
</code></pre>
<p>The difference should be ~0.0001 which looks much better.</p>
<p>Now if you run the optimizer again with the correct version you can see the final weights would be:</p>
<pre><code>[ 0.2  0.2  0.2  0.2  0.2]
</code></pre>
<p>which are exactly what we wanted.</p>
<p><a href="https://www.tensorflow.org/api_guides/python/summary">TensorFlow summaries</a>, and <a href="https://www.tensorflow.org/api_guides/python/tfdbg">tfdbg (TensorFlow Debugger)</a> are other tools that can be used for debugging. Please refer to the official docs to learn more.</p>
<h2 id="numerical-stability-in-tensorflow">Numerical stability in TensorFlow</h2>
<p><a name="stable"></a><br>
When using any numerical computation library such as NumPy or TensorFlow, it's important to note that writing mathematically correct code doesn't necessarily lead to correct results. You also need to make sure that the computations are stable.</p>
<p>Let's start with a simple example. From primary school we know that x * y / y is equal to x for any non zero value of x. But let's see if that's always true in practice:</p>
<pre><code class="language-python">import numpy as np

x = np.float32(1)

y = np.float32(1e-50)  # y would be stored as zero
z = x * y / y

print(z)  # prints nan
</code></pre>
<p>The reason for the incorrect result is that y is simply too small for float32 type. A similar problem occurs when y is too large:</p>
<pre><code class="language-python">y = np.float32(1e39)  # y would be stored as inf
z = x * y / y

print(z)  # prints 0
</code></pre>
<p>The smallest positive value that float32 type can represent is 1.4013e-45 and anything below that would be stored as zero. Also, any number beyond 3.40282e+38, would be stored as inf.</p>
<pre><code class="language-python">print(np.nextafter(np.float32(0), np.float32(1)))  # prints 1.4013e-45
print(np.finfo(np.float32).max)  # print 3.40282e+38
</code></pre>
<p>To make sure that your computations are stable, you want to avoid values with small or very large absolute value. This may sound very obvious, but these kind of problems can become extremely hard to debug especially when doing gradient descent in TensorFlow. This is because you not only need to make sure that all the values in the forward pass are within the valid range of your data types, but also you need to make sure of the same for the backward pass (during gradient computation).</p>
<p>Let's look at a real example. We want to compute the softmax over a vector of logits. A naive implementation would look something like this:</p>
<pre><code class="language-python">import tensorflow as tf

def unstable_softmax(logits):
    exp = tf.exp(logits)
    return exp / tf.reduce_sum(exp)

tf.Session().run(unstable_softmax([1000., 0.]))  # prints [ nan, 0.]
</code></pre>
<p>Note that computing the exponential of logits for relatively small numbers results to gigantic results that are out of float32 range. The largest valid logit for our naive softmax implementation is ln(3.40282e+38) = 88.7, anything beyond that leads to a nan outcome.</p>
<p>But how can we make this more stable? The solution is rather simple. It's easy to see that exp(x - c) / ∑ exp(x - c) = exp(x) / ∑ exp(x). Therefore we can subtract any constant from the logits and the result would remain the same. We choose this constant to be the maximum of logits. This way the domain of the exponential function would be limited to [-inf, 0], and consequently its range would be [0.0, 1.0] which is desirable:</p>
<pre><code class="language-python">import tensorflow as tf

def softmax(logits):
    exp = tf.exp(logits - tf.reduce_max(logits))
    return exp / tf.reduce_sum(exp)

tf.Session().run(softmax([1000., 0.]))  # prints [ 1., 0.]
</code></pre>
<p>Let's look at a more complicated case. Consider we have a classification problem. We use the softmax function to produce probabilities from our logits. We then define our loss function to be the cross entropy between our predictions and the labels. Recall that cross entropy for a categorical distribution can be simply defined as xe(p, q) = -∑ p_i log(q_i). So a naive implementation of the cross entropy would look like this:</p>
<pre><code class="language-python">def unstable_softmax_cross_entropy(labels, logits):
    logits = tf.log(softmax(logits))
    return -tf.reduce_sum(labels * logits)

labels = tf.constant([0.5, 0.5])
logits = tf.constant([1000., 0.])

xe = unstable_softmax_cross_entropy(labels, logits)

print(tf.Session().run(xe))  # prints inf
</code></pre>
<p>Note that in this implementation as the softmax output approaches zero, the log's output approaches infinity which causes instability in our computation. We can rewrite this by expanding the softmax and doing some simplifications:</p>
<pre><code class="language-python">def softmax_cross_entropy(labels, logits):
    scaled_logits = logits - tf.reduce_max(logits)
    normalized_logits = scaled_logits - tf.reduce_logsumexp(scaled_logits)
    return -tf.reduce_sum(labels * normalized_logits)

labels = tf.constant([0.5, 0.5])
logits = tf.constant([1000., 0.])

xe = softmax_cross_entropy(labels, logits)

print(tf.Session().run(xe))  # prints 500.0
</code></pre>
<p>We can also verify that the gradients are also computed correctly:</p>
<pre><code class="language-python">g = tf.gradients(xe, logits)
print(tf.Session().run(g))  # prints [0.5, -0.5]
</code></pre>
<p>which is correct.</p>
<p>Let me remind again that extra care must be taken when doing gradient descent to make sure that the range of your functions as well as the gradients for each layer are within a valid range. Exponential and logarithmic functions when used naively are especially problematic because they can map small numbers to enormous ones and the other way around.</p>
<h2 id="building-a-neural-network-training-framework-with-learn-api">Building a neural network training framework with learn API</h2>
<p><a name="tf_learn"></a><br>
For simplicity, in most of the examples here we manually create sessions and we don't care about saving and loading checkpoints but this is not how we usually do things in practice. You most probably want to use the learn API to take care of session management and logging. We provide a simple but practical <a href="https://github.com/vahidk/TensorflowFramework/tree/master">framework</a> for training neural networks using TensorFlow. In this item we explain how this framework works.</p>
<p>When experimenting with neural network models you usually have a training/test split. You want to train your model on the training set, and once in a while evaluate it on test set and compute some metrics. You also need to store the model parameters as a checkpoint, and ideally you want to be able to stop and resume training. TensorFlow's learn API is designed to make this job easier, letting us focus on developing the actual model.</p>
<p>The most basic way of using tf.learn API is to use tf.Estimator object directly. You need to define a model function that defines a loss function, a train op, one or a set of predictions, and optionally a set of metric ops for evaluation:</p>
<pre><code class="language-python">import tensorflow as tf

def model_fn(features, labels, mode, params):
    predictions = ...
    loss = ...
    train_op = ...
    metric_ops = ...
    return tf.estimator.EstimatorSpec(
        mode=mode,
        predictions=predictions,
        loss=loss,
        train_op=train_op,
        eval_metric_ops=metric_ops)

params = ...
run_config = tf.estimator.RunConfig(model_dir=FLAGS.output_dir)
estimator = tf.estimator.Estimator(
    model_fn=model_fn, config=run_config, params=params)
</code></pre>
<p>To train the model you would then simply call Estimator.train() function while providing an input function to read the data:</p>
<pre><code class="language-python">estimator.train(input_fn=input_fn, max_steps=...)
</code></pre>
<p>and to evaluate the model, simply call Estimator.evaluate():</p>
<pre><code class="language-python">estimator.evaluate(input_fn=input_fn)
</code></pre>
<p>The input function returns two tensors (or dictionaries of tensors) providing the features and labels to be passed to the model:</p>
<pre><code class="language-python">def input_fn():
    features = ...
    labels = ...
    return features, labels
</code></pre>
<p>See <a href="https://github.com/vahidk/TensorflowFramework/blob/master/dataset/mnist.py">mnist.py</a> for an example of how to read your data with the dataset API. To learn about various ways of reading your data in TensorFlow refer to <a href="#data">this item</a>.</p>
<p>The framework also comes with a simple convolutional network classifier in <a href="https://github.com/vahidk/TensorflowFramework/blob/master/model/alexnet.py">alexnet.py</a> that includes an example model.</p>
<p>And that's it! This is all you need to get started with TensorFlow learn API. I recommend to have a look at the framework <a href="https://github.com/vahidk/TensorFlowFramework">source code</a> and see the official python API to learn more about the learn API.</p>
<h1 id="part-ii-tensorflow-cookbook-2">Part II: TensorFlow Cookbook</h1>
<p><a name="cookbook"></a><br>
This section includes implementation of a set of common operations in TensorFlow.</p>
<h3 id="get-shape-a-nameget_shapea">Get shape <a name="get_shape"></a></h3>
<pre><code class="language-python">def get_shape(tensor):
  &quot;&quot;&quot;Returns static shape if available and dynamic shape otherwise.&quot;&quot;&quot;
  static_shape = tensor.shape.as_list()
  dynamic_shape = tf.unstack(tf.shape(tensor))
  dims = [s[1] if s[0] is None else s[0]
          for s in zip(static_shape, dynamic_shape)]
  return dims
</code></pre>
<h3 id="batch-gather-a-namebatch_gathera">Batch Gather <a name="batch_gather"></a></h3>
<pre><code class="language-python">def batch_gather(tensor, indices):
  &quot;&quot;&quot;Gather in batch from a tensor of arbitrary size.

  In pseudocode this module will produce the following:
  output[i] = tf.gather(tensor[i], indices[i])

  Args:
    tensor: Tensor of arbitrary size.
    indices: Vector of indices.
  Returns:
    output: A tensor of gathered values.
  &quot;&quot;&quot;
  shape = get_shape(tensor)
  flat_first = tf.reshape(tensor, [shape[0] * shape[1]] + shape[2:])
  indices = tf.convert_to_tensor(indices)
  offset_shape = [shape[0]] + [1] * (indices.shape.ndims - 1)
  offset = tf.reshape(tf.range(shape[0]) * shape[1], offset_shape)
  output = tf.gather(flat_first, indices + offset)
  return output
</code></pre>
<h3 id="beam-search-a-namebeam_searcha">Beam Search <a name="beam_search"></a></h3>
<pre><code class="language-python">import tensorflow as tf

def rnn_beam_search(update_fn, initial_state, sequence_length, beam_width,
                    begin_token_id, end_token_id, name=&quot;rnn&quot;):
  &quot;&quot;&quot;Beam-search decoder for recurrent models.

  Args:
    update_fn: Function to compute the next state and logits given the current
               state and ids.
    initial_state: Recurrent model states.
    sequence_length: Length of the generated sequence.
    beam_width: Beam width.
    begin_token_id: Begin token id.
    end_token_id: End token id.
    name: Scope of the variables.
  Returns:
    ids: Output indices.
    logprobs: Output log probabilities probabilities.
  &quot;&quot;&quot;
  batch_size = initial_state.shape.as_list()[0]

  state = tf.tile(tf.expand_dims(initial_state, axis=1), [1, beam_width, 1])

  sel_sum_logprobs = tf.log([[1.] + [0.] * (beam_width - 1)])

  ids = tf.tile([[begin_token_id]], [batch_size, beam_width])
  sel_ids = tf.zeros([batch_size, beam_width, 0], dtype=ids.dtype)

  mask = tf.ones([batch_size, beam_width], dtype=tf.float32)

  for i in range(sequence_length):
    with tf.variable_scope(name, reuse=True if i &gt; 0 else None):

      state, logits = update_fn(state, ids)
      logits = tf.nn.log_softmax(logits)

      sum_logprobs = (
          tf.expand_dims(sel_sum_logprobs, axis=2) +
          (logits * tf.expand_dims(mask, axis=2)))

      num_classes = logits.shape.as_list()[-1]

      sel_sum_logprobs, indices = tf.nn.top_k(
          tf.reshape(sum_logprobs, [batch_size, num_classes * beam_width]),
          k=beam_width)

      ids = indices % num_classes

      beam_ids = indices // num_classes

      state = batch_gather(state, beam_ids)

      sel_ids = tf.concat([batch_gather(sel_ids, beam_ids),
                           tf.expand_dims(ids, axis=2)], axis=2)

      mask = (batch_gather(mask, beam_ids) *
              tf.to_float(tf.not_equal(ids, end_token_id)))

  return sel_ids, sel_sum_logprobs
</code></pre>
<h2 id="merge-a-namemergea">Merge <a name="merge"></a></h2>
<pre><code class="language-python">import tensorflow as tf

def merge(tensors, units, activation=tf.nn.relu, name=None, **kwargs):
  &quot;&quot;&quot;Merge features with broadcasting support.

  This operation concatenates multiple features of varying length and applies
  non-linear transformation to the outcome.

  Example:
    a = tf.zeros([m, 1, d1])
    b = tf.zeros([1, n, d2])
    c = merge([a, b], d3)  # shape of c would be [m, n, d3].

  Args:
    tensors: A list of tensor with the same rank.
    units: Number of units in the projection function.
  &quot;&quot;&quot;
  with tf.variable_scope(name, default_name=&quot;merge&quot;):
    # Apply linear projection to input tensors.
    projs = []
    for i, tensor in enumerate(tensors):
      proj = tf.layers.dense(
          tensor, units,
          name=&quot;proj_%d&quot; % i,
          **kwargs)
      projs.append(proj)

    # Compute sum of tensors.
    result = projs.pop()
    for proj in projs:
      result = result + proj

    # Apply nonlinearity.
    if activation:
      result = activation(result)
  return result
</code></pre>
<h2 id="entropy-a-nameentropya">Entropy <a name="entropy"></a></h2>
<pre><code class="language-python">import tensorflow as tf

def softmax_entropy(logits, dim=-1):
  &quot;&quot;&quot;Compute entropy over specified dimensions.&quot;&quot;&quot;
  plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim)
  return -tf.reduce_sum(plogp, dim)
</code></pre>
<h2 id="kl-divergence-a-nameklda">KL-Divergence <a name="kld"></a></h2>
<pre><code class="language-python">def gaussian_kl(q, p=(0., 0.)):
  &quot;&quot;&quot;Computes KL divergence between two isotropic Gaussian distributions.

  To ensure numerical stability, this op uses mu, log(sigma^2) to represent
  the distribution. If q is not provided, it's assumed to be unit Gaussian.

  Args:
    q: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian.
    p: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian.
  Returns:
    A tensor representing KL(q, p).
  &quot;&quot;&quot;
  mu1, log_sigma1_sq = q
  mu2, log_sigma2_sq = p
  return tf.reduce_sum(
    0.5 * (log_sigma2_sq - log_sigma1_sq +
           tf.exp(log_sigma1_sq - log_sigma2_sq) +
           tf.square(mu1 - mu2) / tf.exp(log_sigma2_sq) -
           1), axis=-1)
</code></pre>
<h2 id="make-parallel-a-namemake_parallela">Make parallel <a name="make_parallel"></a></h2>
<pre><code class="language-python">def make_parallel(fn, num_gpus, **kwargs):
  &quot;&quot;&quot;Parallelize given model on multiple gpu devices.

  Args:
    fn: Arbitrary function that takes a set of input tensors and outputs a
        single tensor. First dimension of inputs and output tensor are assumed
        to be batch dimension.
    num_gpus: Number of GPU devices.
    **kwargs: Keyword arguments to be passed to the model.
  Returns:
    A tensor corresponding to the model output.
  &quot;&quot;&quot;
  in_splits = {}
  for k, v in kwargs.items():
    in_splits[k] = tf.split(v, num_gpus)

  out_split = []
  for i in range(num_gpus):
    with tf.device(tf.DeviceSpec(device_type=&quot;GPU&quot;, device_index=i)):
      with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):
        out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))

  return tf.concat(out_split, axis=0)
</code></pre>
<h2 id="leaky-relu-a-nameleaky_relua">Leaky relu <a name="leaky_relu"></a></h2>
<pre><code class="language-python">def leaky_relu(tensor, alpha=0.1):
    &quot;&quot;&quot;Computes the leaky rectified linear activation.&quot;&quot;&quot;
    return tf.maximum(tensor, alpha * tensor)
</code></pre>
<h2 id="batch-normalization-a-namebatch_norma">Batch normalization <a name="batch_norm"></a></h2>
<pre><code class="language-python">def batch_normalization(tensor, training=False, epsilon=0.001, momentum=0.9, 
                        fused_batch_norm=False, name=None):
  &quot;&quot;&quot;Performs batch normalization on given 4-D tensor.
  
  The features are assumed to be in NHWC format. Noe that you need to 
  run UPDATE_OPS in order for this function to perform correctly, e.g.:

  with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):
    train_op = optimizer.minimize(loss)

  Based on: https://arxiv.org/abs/1502.03167
  &quot;&quot;&quot;
  with tf.variable_scope(name, default_name=&quot;batch_normalization&quot;):
    channels = tensor.shape.as_list()[-1]
    axes = list(range(tensor.shape.ndims - 1))

    beta = tf.get_variable(
      'beta', channels, initializer=tf.zeros_initializer())
    gamma = tf.get_variable(
      'gamma', channels, initializer=tf.ones_initializer())

    avg_mean = tf.get_variable(
      &quot;avg_mean&quot;, channels, initializer=tf.zeros_initializer(),
      trainable=False)
    avg_variance = tf.get_variable(
      &quot;avg_variance&quot;, channels, initializer=tf.ones_initializer(),
      trainable=False)

    if training:
      if fused_batch_norm:
        mean, variance = None, None
      else:
        mean, variance = tf.nn.moments(tensor, axes=axes)
    else:
      mean, variance = avg_mean, avg_variance
   
    if fused_batch_norm:
      tensor, mean, variance = tf.nn.fused_batch_norm(
        tensor, scale=gamma, offset=beta, mean=mean, variance=variance, 
        epsilon=epsilon, is_training=training)
    else:
      tensor = tf.nn.batch_normalization(
        tensor, mean, variance, beta, gamma, epsilon)

    if training:
      update_mean = tf.assign(
        avg_mean, avg_mean * momentum + mean * (1.0 - momentum))
      update_variance = tf.assign(
        avg_variance, avg_variance * momentum + variance * (1.0 - momentum))

      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_mean)
      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_variance)

  return tensor
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effective PyTorch]]></title>
        <id>https://fuyunfei.github.io/post/effective-pytorch/</id>
        <link href="https://fuyunfei.github.io/post/effective-pytorch/">
        </link>
        <updated>2020-05-05T03:26:59.000Z</updated>
        <summary type="html"><![CDATA[<p>CC@https://github.com/vahidk/EffectivePyTorch</p>
]]></summary>
        <content type="html"><![CDATA[<p>CC@https://github.com/vahidk/EffectivePyTorch</p>
<!-- more -->
<h1 id="table-of-contents">Table of Contents</h1>
<h2 id="part-i-pytorch-fundamentals">Part I: PyTorch Fundamentals</h2>
<ol>
<li><a href="#basics">PyTorch basics</a></li>
<li><a href="#modules">Encapsulate your model with Modules</a></li>
<li><a href="#broadcast">Broadcasting the good and the ugly</a></li>
<li><a href="#overloaded_ops">Take advantage of the overloaded operators</a></li>
<li><a href="#torchscript">Optimizing runtime with TorchScript</a></li>
<li><a href="#dataloader">Building efficient custom data loaders</a></li>
<li><a href="#stable">Numerical stability in PyTorch</a></li>
</ol>
<hr>
<p><em>To install PyTorch follow the <a href="https://pytorch.org/">instructions on the official website</a>:</em></p>
<pre><code>pip install torch torchvision
</code></pre>
<p><em>We aim to gradually expand this series by adding new articles and keep the content up to date with the latest releases of PyTorch API. If you have suggestions on how to improve this series or find the explanations ambiguous, feel free to create an issue, send patches, or reach out by email.</em></p>
<h1 id="part-i-pytorch-fundamentals-2">Part I: PyTorch Fundamentals</h1>
<p><a name="fundamentals"></a></p>
<h2 id="pytorch-basics">PyTorch basics</h2>
<p><a name="basics"></a><br>
PyTorch is one of the most popular libraries for numerical computation and currently is amongst the most widely used libraries for performing machine learning research. In many ways PyTorch is similar to NumPy, with the additional benefit that PyTorch allows you to perform your computations on CPUs, GPUs, and TPUs without any material change to your code. PyTorch also makes it easy to distribute your computation across multiple devices or machines. One of the most important features of PyTorch is automatic differentiation. It allows computing the gradients of your functions analytically in an efficient manner which is crucial for training machine learning models using gradient descent method. Our goal here is to provide a gentle introduction to PyTorch and discuss best practices for using PyTorch.</p>
<p>The first thing to learn about PyTorch is the concept of Tensors. Tensors are simply multidimensional arrays. A PyTorch Tensor is very similar to a NumPy array with some <s>magical</s> additional functionality.</p>
<p>A tensor can store a scalar value:</p>
<pre><code class="language-python">import torch
a = torch.tensor(3)
print(a)  # tensor(3)
</code></pre>
<p>or an array:</p>
<pre><code class="language-python">b = torch.tensor([1, 2])
print(b)  # tensor([1, 2])
</code></pre>
<p>a matrix:</p>
<pre><code class="language-python">c = torch.zeros([2, 2])
print(c)  # tensor([[0., 0.], [0., 0.]])
</code></pre>
<p>or any arbitrary dimensional tensor:</p>
<pre><code class="language-python">d = torch.rand([2, 2, 2])
</code></pre>
<p>Tensors can be used to perform algebraic operations efficiently. One of the most commonly used operations in machine learning applications is matrix multiplication. Say you want to multiply two random matrices of size 3x5 and 5x4, this can be done with the matrix multiplication (@) operation:</p>
<pre><code class="language-python">import torch

x = torch.randn([3, 5])
y = torch.randn([5, 4])
z = x @ y

print(z)
</code></pre>
<p>Similarly, to add two vectors, you can do:</p>
<pre><code class="language-python">z = x + y
</code></pre>
<p>To convert a tensor into a numpy array you can call Tensor's numpy() method:</p>
<pre><code class="language-python">print(z.numpy())
</code></pre>
<p>And you can always convert a numpy array into a tensor by:</p>
<pre><code class="language-python">x = torch.tensor(np.random.normal([3, 5]))
</code></pre>
<h3 id="automatic-differentiation">Automatic differentiation</h3>
<p>The most important advantage of PyTorch over NumPy is its automatic differentiation functionality which is very useful in optimization applications such as optimizing parameters of a neural network. Let's try to understand it with an example.</p>
<p>Say you have a composite function which is a chain of two functions: <code>g(u(x))</code>.<br>
To compute the derivative of <code>g</code> with respect to <code>x</code> we can use the chain rule which states that: <code>dg/dx = dg/du * du/dx</code>. PyTorch can analytically compute the derivatives for us.</p>
<p>To compute the derivatives in PyTorch first we create a tensor and set its <code>requires_grad</code> to true. We can use tensor operations to define our functions. We assume <code>u</code> is a quadratic function and <code>g</code> is a simple linear function:</p>
<pre><code class="language-python">x = torch.tensor(1.0, requires_grad=True)

def u(x):
  return x * x

def g(u):
  return -u
</code></pre>
<p>In this case our composite function is <code>g(u(x)) = -x*x</code>. So its derivative with respect to <code>x</code> is <code>-2x</code>. At point <code>x=1</code>, this is equal to <code>-2</code>.</p>
<p>Let's verify this. This can be done using grad function in PyTorch:</p>
<pre><code class="language-python">dgdx = torch.autograd.grad(g(u(x)), x)[0]
print(dgdx)  # tensor(-2.)
</code></pre>
<h3 id="curve-fitting">Curve fitting</h3>
<p>To understand how powerful automatic differentiation can be let's have a look at another example. Assume that we have samples from a curve (say <code>f(x) = 5x^2 + 3</code>) and we want to estimate <code>f(x)</code> based on these samples. We define a parametric function <code>g(x, w) = w0 x^2 + w1 x + w2</code>, which is a function of the input <code>x</code> and latent parameters <code>w</code>, our goal is then to find the latent parameters such that <code>g(x, w) ≈ f(x)</code>. This can be done by minimizing the following loss function: <code>L(w) = Σ (f(x) - g(x, w))^2</code>. Although there's a closed form solution for this simple problem, we opt to use a more general approach that can be applied to any arbitrary differentiable function, and that is using stochastic gradient descent. We simply compute the average gradient of <code>L(w)</code> with respect to <code>w</code> over a set of sample points and move in the opposite direction.</p>
<p>Here's how it can be done in PyTorch:</p>
<pre><code class="language-python">import numpy as np
import torch

# Assuming we know that the desired function is a polynomial of 2nd degree, we
# allocate a vector of size 3 to hold the coefficients and initialize it with
# random noise.
w = torch.tensor(torch.randn([3, 1]), requires_grad=True)

# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.
opt = torch.optim.Adam([w], 0.1)

def model(x):
    # We define yhat to be our estimate of y.
    f = torch.stack([x * x, x, torch.ones_like(x)], 1)
    yhat = torch.squeeze(f @ w, 1)
    return yhat

def compute_loss(y, yhat):
    # The loss is defined to be the mean squared error distance between our
    # estimate of y and its true value. 
    loss = torch.nn.functional.mse_loss(yhat, y)
    return loss

def generate_data():
    # Generate some training data based on the true function
    x = torch.rand(100) * 20 - 10
    y = 5 * x * x + 3
    return x, y

def train_step():
    x, y = generate_data()

    yhat = model(x)
    loss = compute_loss(y, yhat)

    opt.zero_grad()
    loss.backward()
    opt.step()

for _ in range(1000):
    train_step()

print(w.detach().numpy())
</code></pre>
<p>By running this piece of code you should see a result close to this:</p>
<pre><code class="language-python">[4.9924135, 0.00040895029, 3.4504161]
</code></pre>
<p>Which is a relatively close approximation to our parameters.</p>
<p>This is just tip of the iceberg for what PyTorch can do. Many problems such as optimizing large neural networks with millions of parameters can be implemented efficiently in PyTorch in just a few lines of code. PyTorch takes care of scaling across multiple devices, and threads, and supports a variety of platforms.</p>
<h2 id="encapsulate-your-model-with-modules">Encapsulate your model with Modules</h2>
<p><a name="modules"></a><br>
In the previous example we used bare bone tensors and tensor operations to build our model. To make your code slightly more organized it's recommended to use PyTorch's modules. A module is simply a container for your parameters and encapsulates model operations. For example say you want to represent a linear model <code>y = ax + b</code>. This model can be represented with the following code:</p>
<pre><code class="language-python">import torch

class Net(torch.nn.Module):

  def __init__(self):
    super().__init__()
    self.a = torch.nn.Parameter(torch.rand(1))
    self.b = torch.nn.Parameter(torch.rand(1))

  def forward(self, x):
    yhat = self.a * x + self.b
    return yhat
</code></pre>
<p>To use this model in practice you instantiate the module and simply call it like a function:</p>
<pre><code class="language-python">x = torch.arange(100, dtype=torch.float32)

net = Net()
y = net(x)
</code></pre>
<p>Parameters are essentially tensors with <code>requires_grad</code> set to true. It's convenient to use parameters because you can simply retrieve them all with module's <code>parameters()</code> method:</p>
<pre><code class="language-python">for p in net.parameters():
    print(p)
</code></pre>
<p>Now, say you have an unknown function <code>y = 5x + 3 + some noise</code>, and you want to optimize the parameters of your model to fit this function.  You can start by sampling some points from your function:</p>
<pre><code class="language-python">x = torch.arange(100, dtype=torch.float32) / 100
y = 5 * x + 3 + torch.rand(100) * 0.3
</code></pre>
<p>Similar to the previous example, you can define a loss function and optimize the parameters of your model as follows:</p>
<pre><code class="language-python">criterion = torch.nn.MSELoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.01)

for i in range(10000):
  net.zero_grad()
  yhat = net(x)
  loss = criterion(yhat, y)
  loss.backward()
  optimizer.step()

print(net.a, net.b) # Should be close to 5 and 3
</code></pre>
<p>PyTorch comes with a number of predefined modules. One such module is <code>torch.nn.Linear</code> which is a more general form of a linear function than what we defined above. We can rewrite our module above using <code>torch.nn.Linear</code> like this:</p>
<pre><code class="language-python">class Net(torch.nn.Module):

  def __init__(self):
    super().__init__()
    self.linear = torch.nn.Linear(1, 1)

  def forward(self, x):
    yhat = self.linear(x.unsqueeze(1)).squeeze(1)
    return yhat
</code></pre>
<p>Note that we used squeeze and unsqueeze since <code>torch.nn.Linear</code> operates on batch of vectors as opposed to scalars.</p>
<p>By default calling parameters() on a module will return the parameters of all its submodules:</p>
<pre><code class="language-python">net = Net()
for p in net.parameters():
    print(p)
</code></pre>
<p>There are some predefined modules that act as a container for other modules. The most commonly used container module is <code>torch.nn.Sequential</code>. As its name implies it's used to to stack multiple modules (or layers) on top of each other. For example to stack two Linear layers with a <code>ReLU</code> nonlinearity in between you can do:</p>
<pre><code class="language-python">model = torch.nn.Sequential(
    torch.nn.Linear(64, 32),
    torch.nn.ReLU(),
    torch.nn.Linear(32, 10),
)
</code></pre>
<h2 id="broadcasting-the-good-and-the-ugly">Broadcasting the good and the ugly</h2>
<p><a name="broadcast"></a><br>
PyTorch supports broadcasting elementwise operations. Normally when you want to perform operations like addition and multiplication, you need to make sure that shapes of the operands match, e.g. you can’t add a tensor of shape <code>[3, 2]</code> to a tensor of shape <code>[3, 4]</code>. But there’s a special case and that’s when you have a singular dimension. PyTorch implicitly tiles the tensor across its singular dimensions to match the shape of the other operand. So it’s valid to add a tensor of shape <code>[3, 2]</code> to a tensor of shape <code>[3, 1]</code>.</p>
<pre><code class="language-python">import torch

a = torch.tensor([[1., 2.], [3., 4.]])
b = torch.tensor([[1.], [2.]])
# c = a + b.repeat([1, 2])
c = a + b

print(c)
</code></pre>
<p>Broadcasting allows us to perform implicit tiling which makes the code shorter, and more memory efficient, since we don’t need to store the result of the tiling operation. One neat place that this can be used is when combining features of varying length. In order to concatenate features of varying length we commonly tile the input tensors, concatenate the result and apply some nonlinearity. This is a common pattern across a variety of neural network architectures:</p>
<pre><code class="language-python">a = torch.rand([5, 3, 5])
b = torch.rand([5, 1, 6])

linear = torch.nn.Linear(11, 10)

# concat a and b and apply nonlinearity
tiled_b = b.repeat([1, 3, 1])
c = torch.cat([a, tiled_b], 2)
d = torch.nn.functional.relu(linear(c))

print(d.shape)  # torch.Size([5, 3, 10])
</code></pre>
<p>But this can be done more efficiently with broadcasting. We use the fact that <code>f(m(x + y))</code> is equal to <code>f(mx + my)</code>. So we can do the linear operations separately and use broadcasting to do implicit concatenation:</p>
<pre><code class="language-python">a = torch.rand([5, 3, 5])
b = torch.rand([5, 1, 6])

linear1 = torch.nn.Linear(5, 10)
linear2 = torch.nn.Linear(6, 10)

pa = linear1(a)
pb = linear2(b)
d = torch.nn.functional.relu(pa + pb)

print(d.shape)  # torch.Size([5, 3, 10])
</code></pre>
<p>In fact this piece of code is pretty general and can be applied to tensors of arbitrary shape as long as broadcasting between tensors is possible:</p>
<pre><code class="language-python">class Merge(torch.nn.Module):
    def __init__(self, in_features1, in_features2, out_features, activation=None):
        super().__init__()
        self.linear1 = torch.nn.Linear(in_features1, out_features)
        self.linear2 = torch.nn.Linear(in_features2, out_features)
        self.activation = activation

    def forward(self, a, b):
        pa = self.linear1(a)
        pb = self.linear2(b)
        c = pa + pb
        if self.activation is not None:
            c = self.activation(c)
        return c
</code></pre>
<p>So far we discussed the good part of broadcasting. But what’s the ugly part you may ask? Implicit assumptions almost always make debugging harder to do. Consider the following example:</p>
<pre><code class="language-python">a = torch.tensor([[1.], [2.]])
b = torch.tensor([1., 2.])
c = torch.sum(a + b)

print(c)
</code></pre>
<p>What do you think the value of <code>c</code> would be after evaluation? If you guessed 6, that’s wrong. It’s going to be 12. This is because when rank of two tensors don’t match, PyTorch automatically expands the first dimension of the tensor with lower rank before the elementwise operation, so the result of addition would be <code>[[2, 3], [3, 4]]</code>, and the reducing over all parameters would give us 12.</p>
<p>The way to avoid this problem is to be as explicit as possible. Had we specified which dimension we would want to reduce across, catching this bug would have been much easier:</p>
<pre><code class="language-python">a = torch.tensor([[1.], [2.]])
b = torch.tensor([1., 2.])
c = torch.sum(a + b, 0)

print(c)
</code></pre>
<p>Here the value of <code>c</code> would be <code>[5, 7]</code>, and we immediately would guess based on the shape of the result that there’s something wrong. A general rule of thumb is to always specify the dimensions in reduction operations and when using <code>torch.squeeze</code>.</p>
<h2 id="take-advantage-of-the-overloaded-operators">Take advantage of the overloaded operators</h2>
<p><a name="overloaded_ops"></a><br>
Just like NumPy, PyTorch overloads a number of python operators to make PyTorch code shorter and more readable.</p>
<p>The slicing op is one of the overloaded operators that can make indexing tensors very easy:</p>
<pre><code class="language-python">z = x[begin:end]  # z = torch.narrow(0, begin, end-begin)
</code></pre>
<p>Be very careful when using this op though. The slicing op, like any other op, has some overhead. Because it's a common op and innocent looking it may get overused a lot which may lead to inefficiencies. To understand how inefficient this op can be let's look at an example. We want to manually perform reduction across the rows of a matrix:</p>
<pre><code class="language-python">import torch
import time

x = torch.rand([500, 10])

z = torch.zeros([10])

start = time.time()
for i in range(500):
    z += x[i]
print(&quot;Took %f seconds.&quot; % (time.time() - start))
</code></pre>
<p>This runs quite slow and the reason is that we are calling the slice op 500 times, which adds a lot of overhead. A better choice would have been to use <code>torch.unbind</code> op to slice the matrix into a list of vectors all at once:</p>
<pre><code class="language-python">z = torch.zeros([10])
for x_i in torch.unbind(x):
    z += x_i
</code></pre>
<p>This is significantly (~30% on my machine) faster.</p>
<p>Of course, the right way to do this simple reduction is to use <code>torch.sum</code> op to this in one op:</p>
<pre><code class="language-python">z = torch.sum(x, dim=0)
</code></pre>
<p>which is extremely fast (~100x faster on my machine).</p>
<p>PyTorch also overloads a range of arithmetic and logical operators:</p>
<pre><code class="language-python">z = -x  # z = torch.neg(x)
z = x + y  # z = torch.add(x, y)
z = x - y
z = x * y  # z = torch.mul(x, y)
z = x / y  # z = torch.div(x, y)
z = x // y
z = x % y
z = x ** y  # z = torch.pow(x, y)
z = x @ y  # z = torch.matmul(x, y)
z = x &gt; y
z = x &gt;= y
z = x &lt; y
z = x &lt;= y
z = abs(x)  # z = torch.abs(x)
z = x &amp; y
z = x | y
z = x ^ y  # z = torch.logical_xor(x, y)
z = ~x  # z = torch.logical_not(x)
z = x == y  # z = torch.eq(x, y)
z = x != y  # z = torch.ne(x, y)
</code></pre>
<p>You can also use the augmented version of these ops. For example <code>x += y</code> and <code>x **= 2</code> are also valid.</p>
<p>Note that Python doesn't allow overloading <code>and</code>, <code>or</code>, and <code>not</code> keywords.</p>
<h2 id="optimizing-runtime-with-torchscript">Optimizing runtime with TorchScript</h2>
<p><a name="torchscript"></a><br>
PyTorch is optimized to perform operations on large tensors. Doing many operations on small tensors is quite inefficient in PyTorch. So, whenever possible you should rewrite your computations in batch form to reduce overhead and improve performance. If there's no way you can manually batch your operations, using TorchScript may improve your code's performance. TorchScript is simply a subset of Python functions that are recognized by PyTorch. PyTorch can automatically optimize your TorchScript code using its just in time (jit) compiler and reduce some overheads.</p>
<p>Let's look at an example. A very common operation in ML applications is &quot;batch gather&quot;. This operation can simply written as <code>output[i] = input[i, index[i]]</code>. This can be simply implemented in PyTorch as follows:</p>
<pre><code class="language-python">import torch
def batch_gather(tensor, indices):
    output = []
    for i in range(tensor.size(0)):
        output += [tensor[i][indices[i]]]
    return torch.stack(output)
</code></pre>
<p>To implement the same function using TorchScript simply use the <code>torch.jit.script</code> decorator:</p>
<pre><code class="language-python">@torch.jit.script
def batch_gather_jit(tensor, indices):
    output = []
    for i in range(tensor.size(0)):
        output += [tensor[i][indices[i]]]
    return torch.stack(output)
</code></pre>
<p>On my tests this is about 10% faster.</p>
<p>But nothing beats manually batching your operations. A vectorized implementation in my tests is 100 times faster:</p>
<pre><code class="language-python">def batch_gather_vec(tensor, indices):
    shape = list(tensor.shape)
    flat_first = torch.reshape(
        tensor, [shape[0] * shape[1]] + shape[2:])
    offset = torch.reshape(
        torch.arange(shape[0]).cuda() * shape[1],
        [shape[0]] + [1] * (len(indices.shape) - 1))
    output = flat_first[indices + offset]
    return output
</code></pre>
<h2 id="building-efficient-custom-data-loaders">Building efficient custom data loaders</h2>
<p><a name="dataloader"></a></p>
<p>In the last lesson we talked about writing efficient PyTorch code. But to make your code run with maximum efficiency you also need to load your data efficiently into your device's memory. Fortunately PyTorch offers a tool to make data loading easy. It's called a <code>DataLoader</code>. A <code>DataLoader</code> uses multiple workers to simultanously load data from a <code>Dataset</code> and optionally uses a <code>Sampler</code> to sample data entries and form a batch.</p>
<p>If you can randomly access your data, using a <code>DataLoader</code> is very easy: You simply need to implement a <code>Dataset</code> class that implements <code>__getitem__</code> (to read each data item) and <code>__len__</code> (to return the number of items in the dataset) methods. For example here's how to load images from a given directory:</p>
<pre><code class="language-python">import glob
import os
import random
import cv2
import torch

class ImageDirectoryDataset(torch.utils.data.Dataset):
    def __init__(path, pattern):
        self.paths = list(glob.glob(os.path.join(path, pattern)))

    def __len__(self):
        return len(self.paths)

    def __item__(self):
        path = random.choice(paths)
        return cv2.imread(path, 1)
</code></pre>
<p>To load all jpeg images from a given directory you can then do the following:</p>
<pre><code class="language-python">dataloader = torch.utils.data.DataLoader(ImageDirectoryDataset(&quot;/data/imagenet/*.jpg&quot;), num_workers=8)
for data in dataloader:
    # do something with data
</code></pre>
<p>Here we are using 8 workers to simultanously read our data from the disk. You can tune the number of workers on your machine for optimal results.</p>
<p>Using a <code>DataLoader</code> to read data with random access may be ok if you have fast storage or if your data items are large. But imagine having a network file system with slow connection. Requesting individual files this way can be extremely slow and would probably end up becoming the bottleneck of your training pipeline.</p>
<p>A better approach is to store your data in a contiguous file format which can be read sequentially. For example if you have a large collection of images you can use tar to create a single archive and extract files from the archive sequentially in python. To do this you can use PyTorch's <code>IterableDataset</code>. To create an <code>IterableDataset</code> class you only need to implement an <code>__iter__</code> method which sequentially reads and yields data items from the dataset.</p>
<p>A naive implementation would like this:</p>
<pre><code class="language-python">import tarfile
import torch

def tar_image_iterator(path):
    tar = tarfile.open(self.path, &quot;r&quot;)
    for tar_info in tar:
        file = tar.extractfile(tar_info)
        content = file.read()
        yield cv2.imdecode(content, 1)
        file.close()
        tar.members = []
    tar.close()

class TarImageDataset(torch.utils.data.IterableDataset):
    def __init__(self, path):
        super().__init__()
        self.path = path

    def __iter__(self):
        yield from tar_image_iterator(self.path)
</code></pre>
<p>But there's a major problem with this implementation. If you try to use DataLoader to read from this dataset with more than one worker you'd observe a lot of duplicated images:</p>
<pre><code class="language-python">dataloader = torch.utils.data.DataLoader(TarImageDataset(&quot;/data/imagenet.tar&quot;), num_workers=8)
for data in dataloader:
    # data contains duplicated items
</code></pre>
<p>The problem is that each worker creates a separate instance of the dataset and each would start from the beginning of the dataset. One way to avoid this is to instead of having one tar file, split your data into <code>num_workers</code> separate tar files and load each with a separate worker:</p>
<pre><code class="language-python">class TarImageDataset(torch.utils.data.IterableDataset):
    def __init__(self, paths):
        super().__init__()
        self.paths = paths

    def __iter__(self):
        worker_info = torch.utils.data.get_worker_info()
        # For simplicity we assume num_workers is equal to number of tar files
        if worker_info is None or worker_info.num_workers != len(self.paths):
            raise ValueError(&quot;Number of workers doesn't match number of files.&quot;)
        yield from tar_image_iterator(self.paths[worker_info.worker_id])
</code></pre>
<p>This is how our dataset class can be used:</p>
<pre><code class="language-python">dataloader = torch.utils.data.DataLoader(
    TarImageDataset([&quot;/data/imagenet_part1.tar&quot;, &quot;/data/imagenet_part2.tar&quot;]), num_workers=2)
for data in dataloader:
    # do something with data
</code></pre>
<p>We discussed a simple strategy to avoid duplicated entries problem. <a href="https://github.com/vahidk/tfrecord">tfrecord</a> package uses slightly more sophisticated strategies to shard your data on the fly.</p>
<h2 id="numerical-stability-in-pytorch">Numerical stability in PyTorch</h2>
<p><a name="stable"></a><br>
When using any numerical computation library such as NumPy or PyTorch, it's important to note that writing mathematically correct code doesn't necessarily lead to correct results. You also need to make sure that the computations are stable.</p>
<p>Let's start with a simple example. Mathematically, it's easy to see that <code>x * y / y = x</code> for any non zero value of <code>x</code>. But let's see if that's always true in practice:</p>
<pre><code class="language-python">import numpy as np

x = np.float32(1)

y = np.float32(1e-50)  # y would be stored as zero
z = x * y / y

print(z)  # prints nan
</code></pre>
<p>The reason for the incorrect result is that <code>y</code> is simply too small for float32 type. A similar problem occurs when <code>y</code> is too large:</p>
<pre><code class="language-python">y = np.float32(1e39)  # y would be stored as inf
z = x * y / y

print(z)  # prints nan
</code></pre>
<p>The smallest positive value that float32 type can represent is 1.4013e-45 and anything below that would be stored as zero. Also, any number beyond 3.40282e+38, would be stored as inf.</p>
<pre><code class="language-python">print(np.nextafter(np.float32(0), np.float32(1)))  # prints 1.4013e-45
print(np.finfo(np.float32).max)  # print 3.40282e+38
</code></pre>
<p>To make sure that your computations are stable, you want to avoid values with small or very large absolute value. This may sound very obvious, but these kind of problems can become extremely hard to debug especially when doing gradient descent in PyTorch. This is because you not only need to make sure that all the values in the forward pass are within the valid range of your data types, but also you need to make sure of the same for the backward pass (during gradient computation).</p>
<p>Let's look at a real example. We want to compute the softmax over a vector of logits. A naive implementation would look something like this:</p>
<pre><code class="language-python">import torch

def unstable_softmax(logits):
    exp = torch.exp(logits)
    return exp / torch.sum(exp)

print(unstable_softmax(torch.tensor([1000., 0.])).numpy())  # prints [ nan, 0.]
</code></pre>
<p>Note that computing the exponential of logits for relatively small numbers results to gigantic results that are out of float32 range. The largest valid logit for our naive softmax implementation is <code>ln(3.40282e+38) = 88.7</code>, anything beyond that leads to a nan outcome.</p>
<p>But how can we make this more stable? The solution is rather simple. It's easy to see that <code>exp(x - c) Σ exp(x - c) = exp(x) / Σ exp(x)</code>. Therefore we can subtract any constant from the logits and the result would remain the same. We choose this constant to be the maximum of logits. This way the domain of the exponential function would be limited to <code>[-inf, 0]</code>, and consequently its range would be <code>[0.0, 1.0]</code> which is desirable:</p>
<pre><code class="language-python">import torch

def softmax(logits):
    exp = torch.exp(logits - torch.reduce_max(logits))
    return exp / torch.sum(exp)

print(softmax(torch.tensor([1000., 0.])).numpy())  # prints [ 1., 0.]
</code></pre>
<p>Let's look at a more complicated case. Consider we have a classification problem. We use the softmax function to produce probabilities from our logits. We then define our loss function to be the cross entropy between our predictions and the labels. Recall that cross entropy for a categorical distribution can be simply defined as <code>xe(p, q) = -Σ p_i log(q_i)</code>. So a naive implementation of the cross entropy would look like this:</p>
<pre><code class="language-python">def unstable_softmax_cross_entropy(labels, logits):
    logits = torch.log(softmax(logits))
    return -torch.sum(labels * logits)

labels = torch.tensor([0.5, 0.5])
logits = torch.tensor([1000., 0.])

xe = unstable_softmax_cross_entropy(labels, logits)

print(xe.numpy())  # prints inf
</code></pre>
<p>Note that in this implementation as the softmax output approaches zero, the log's output approaches infinity which causes instability in our computation. We can rewrite this by expanding the softmax and doing some simplifications:</p>
<pre><code class="language-python">def softmax_cross_entropy(labels, logits, dim=-1):
    scaled_logits = logits - torch.max(logits)
    normalized_logits = scaled_logits - torch.logsumexp(scaled_logits, dim)
    return -torch.sum(labels * normalized_logits)

labels = torch.tensor([0.5, 0.5])
logits = torch.tensor([1000., 0.])

xe = softmax_cross_entropy(labels, logits)

print(xe.numpy())  # prints 500.0
</code></pre>
<p>We can also verify that the gradients are also computed correctly:</p>
<pre><code class="language-python">logits.requires_grad_(True)
xe = softmax_cross_entropy(labels, logits)
g = torch.autograd.grad(xe, logits)[0]
print(g.numpy())  # prints [0.5, -0.5]
</code></pre>
<p>Let me remind again that extra care must be taken when doing gradient descent to make sure that the range of your functions as well as the gradients for each layer are within a valid range. Exponential and logarithmic functions when used naively are especially problematic because they can map small numbers to enormous ones and the other way around.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Business Plan]]></title>
        <id>https://fuyunfei.github.io/post/business-plan/</id>
        <link href="https://fuyunfei.github.io/post/business-plan/">
        </link>
        <updated>2020-05-01T03:18:43.000Z</updated>
        <content type="html"><![CDATA[<p>制作BP（Business Plan）<br>
- 对于拉融资来说BP起到了至关重要的作用<br>
- 很多人不写BP或是有许多人常写却写不好<br>
- 公司也好个人也罢都应该把BP认真准备好<br>
- 学习制作BP可以锻炼商业理解与整理思路<br>
- BP起到的作用不限于融资也可以寻求合伙</p>
<p>BP的格式建议：<br>
- 正常情况下选择PPT（幻灯片）或PDF作为制作格式<br>
- BP没有标准格式<br>
- 李自然通常使用Keynote制作然后导出PDF格式<br>
- 文件大小压缩至2M<br>
- 内容字体要大，要在手机上进行效果预览的检查<br>
- BP的长度尽可能控制在20页以内<br>
- 配合的演讲时长控制在30分钟以内</p>
<p>核心建议：<br>
1.团队，操盘项目的是一群怎么样的人？<br>
2.内容，项目是在做什么？解决了什么市场需求？<br>
3.规模，项目的市场规模到底有多大？<br>
4.商业模式，这个项目如何赚钱？收入构成与收入预测<br>
5.核心优势，核心的优势在什么地方？<br>
6.关键数据，多维度的关键数据<br>
7.竞争对手，项目与主要竞争对手的关系<br>
8.财务状况，支出与未来的财务规划<br>
9.路线图，过去做了什么、现在要做什么、未来要做什么，时间节点如何规划？<br>
10.融资，准备融资规模、估值、股权结构</p>
<p>常规建议<br>
1.BP必须是创始人制作并且可以进行演讲<br>
2.准备好30分钟的逐字稿+练好口活<br>
3.准备好各个时长的版本包括15min、5min，各版本内容的调整<br>
4.多练习，有条件的可以寻求有经验的朋友进行帮助练习</p>
<p>常犯错误<br>
- BP并非详细的商业计划，最大作用是勾起投资人对项目的兴趣<br>
- 内容不用面面俱到，有理有据即可<br>
- 不用担心内容以偏概全，没说清楚<br>
- BP仅作为敲门砖，真正的谈判还是面对面的线下<br>
- BP的字不用太多，演讲不要照稿念<br>
- 套话不要多，话术尽可能简洁明了，说人话</p>
<p>内容重点：<br>
- 突出增长<br>
- 投资上高增长项目最抢手也更吸引人，合作上突出增长代表更有未来，寻求合作也会变的轻松<br>
- 关键的增长数据，尽可能阐述过程而非直接给出一个数值，有条件可以制作成可视化的图片<br>
- 突出盈利<br>
- 大环境越好越突出增长，大环境越差尽可能突出盈利<br>
- 团队的执行能力，一切的投资都是投人<br>
- 突出CEO的能力<br>
- 为什么你们的团队是最适合团队，展示过往资历与特质<br>
- 团队做了什么？进行了哪些调整？</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Depthwise Convolution]]></title>
        <id>https://fuyunfei.github.io/post/depthwise-convolution/</id>
        <link href="https://fuyunfei.github.io/post/depthwise-convolution/">
        </link>
        <updated>2019-11-11T03:56:08.000Z</updated>
        <content type="html"><![CDATA[<!-- Comparing Normal Convolution to Depthwise Convolution -->
<h2 id="normal-convolution"><strong>Normal Convolution</strong></h2>
<figure data-type="image" tabindex="1"><img src="https://fuyunfei.github.io/post-images/1573588680034.png" alt="" width="400" loading="lazy"></figure>
<h2 id="depthwise-convolution"><strong>Depthwise Convolution</strong></h2>
<figure data-type="image" tabindex="2"><img src="https://fuyunfei.github.io/post-images/1573588686254.png" alt="" width="600" loading="lazy"></figure>
<h2 id="depthwise-seperatable-convolution"><strong>Depthwise Seperatable Convolution</strong></h2>
<figure data-type="image" tabindex="3"><img src="https://fuyunfei.github.io/post-images/1573588698538.png" alt="" width="600" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RL 总结]]></title>
        <id>https://fuyunfei.github.io/post/rl-zong-jie/</id>
        <link href="https://fuyunfei.github.io/post/rl-zong-jie/">
        </link>
        <updated>2019-10-30T12:30:50.000Z</updated>
        <content type="html"><![CDATA[<h3 id="model-free-和-model-based">Model-free 和 Model-based</h3>
<p>我们可以将所有强化学习的方法分为理不理解所处环境,如果我们不尝试去理解环境, 环境给了我们什么就是什么. 我们就把这种方法叫做 model-free, 这里的 model 就是用模型来表示环境, 那理解了环境也就是学会了用一个模型来代表环境, 所以这种就是 model-based 方法.</p>
<p>Model-free 的方法有很多, 像 Qlearning, Sarsa, Policy Gradients 都是从环境中得到反馈然后从中学习. 而 model-based RL 只是多了一道程序, 为真实世界建模, 也可以说他们都是 model-free 的强化学习, 只是 model-based 多出了一个虚拟环境, 我们不仅可以像 model-free 那样在现实中玩耍,还能在游戏中玩耍, 而玩耍的方式也都是 model-free 中那些玩耍方式, 最终 model-based 还有一个杀手锏是 model-free 超级羡慕的. 那就是想象力.</p>
<h3 id="基于概率policy-based-和-基于价值-value-based">基于概率(Policy based) 和 基于价值 (Value based)</h3>
<p>基于概率是强化学习中最直接的一种, 他能通过感官分析所处的环境, 直接输出下一步要采取的各种动作的概率, 然后根据概率采取行动, 所以每种动作都有可能被选中, 只是可能性不同. 而基于价值的方法输出则是所有动作的价值, 我们会根据最高价值来选着动作, 相比基于概率的方法, 基于价值的决策部分更为铁定, 毫不留情, 就选价值最高的, 而基于概率的, 即使某个动作的概率最高, 但是还是不一定会选到他.</p>
<p>我们现在说的动作都是一个一个不连续的动作, 而对于选取连续的动作, 基于价值的方法是无能为力的. 我们却能用一个概率分布在连续动作中选取特定动作, 这也是基于概率的方法的优点之一. 那么这两类使用的方法又有哪些呢?</p>
<p>比如在基于概率这边, 有 policy gradients, 在基于价值这边有 q learning, sarsa 等. 而且我们还能结合这两类方法的优势之处, 创造更牛逼的一种方法, 叫做 actor-critic, actor 会基于概率做出动作, 而 critic 会对做出的动作给出动作的价值, 这样就在原有的 policy gradients 上加速了学习过程.</p>
<h3 id="回合更新-和-单步更新">回合更新 和 单步更新</h3>
<p>强化学习还能用另外一种方式分类, 回合更新和单步更新, 想象强化学习就是在玩游戏, 游戏回合有开始和结束. 回合更新指的是游戏开始后, 我们要等待游戏结束, 然后再总结这一回合中的所有转折点, 再更新我们的行为准则. 而单步更新则是在游戏进行中每一步都在更新, 不用等待游戏的结束, 这样我们就能边玩边学习了.</p>
<p>再来说说方法, Monte-carlo learning 和基础版的 policy gradients 等 都是回合更新制, Qlearning, Sarsa, 升级版的 policy gradients 等都是单步更新制. 因为单步更新更有效率, 所以现在大多方法都是基于单步更新. 比如有的强化学习问题并不属于回合问题.</p>
<h3 id="在线学习-和-离线学习">在线学习 和 离线学习</h3>
<p>这个视频的最后一种分类方式是 在线学习和离线学习, 所谓在线学习, 就是指我必须本人在场, 并且一定是本人边玩边学习, 而离线学习是你可以选择自己玩, 也可以选择看着别人玩, 通过看别人玩来学习别人的行为准则, 离线学习 同样是从过往的经验中学习, 但是这些过往的经历没必要是自己的经历, 任何人的经历都能被学习. 或者我也不必要边玩边学习, 我可以白天先存储下来玩耍时的记忆, 然后晚上通过离线学习来学习白天的记忆.那么每种学习的方法又有哪些呢?</p>
<p>最典型的在线学习就是 sarsa 了, 还有一种优化 sarsa 的算法, 叫做 sarsa lambda, 最典型的离线学习就是 Q learning, 后来人也根据离线学习的属性, 开发了更强大的算法, 比如让计算机学会玩电动的 Deep-Q-Network.</p>
<p>Q Learning :</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo>(</mo><mstyle mathsize="0.9em"><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mstyle><mo separator="true">,</mo><mstyle mathsize="0.9em"><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mstyle><mo>)</mo><mo>←</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo>)</mo><mi>Q</mi><mo>(</mo><mstyle mathsize="0.9em"><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mstyle><mo separator="true">,</mo><mstyle mathsize="0.9em"><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mstyle><mo>)</mo><mo>+</mo><mi>α</mi><mo fence="false">(</mo><mstyle mathsize="0.9em"><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi></mstyle><mo>+</mo><mi>γ</mi><munder><mi>max</mi><mo>⁡</mo><mi>a</mi></munder><mi>Q</mi><mo>(</mo><mstyle mathsize="0.9em"><mi>n</mi><mi>e</mi><mi>x</mi><mi>t</mi><mtext> </mtext><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mstyle><mo separator="true">,</mo><mstyle mathsize="0.9em"><mi>a</mi><mi>l</mi><mi>l</mi><mtext> </mtext><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mstyle><mo>)</mo><mo fence="false">)</mo></mrow><annotation encoding="application/x-tex">Q({\small state}, {\small action}) \leftarrow (1 - \alpha) Q({\small state}, {\small action}) + \alpha \Big({\small reward} + \gamma \max_{a} Q({\small next \ state}, {\small all \ actions})\Big) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">s</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">e</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">c</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">i</span><span class="mord mathdefault sizing reset-size6 size5">o</span><span class="mord mathdefault sizing reset-size6 size5">n</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">s</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">e</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">c</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">i</span><span class="mord mathdefault sizing reset-size6 size5">o</span><span class="mord mathdefault sizing reset-size6 size5">n</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mord"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5" style="margin-right:0.02778em;">r</span><span class="mord mathdefault sizing reset-size6 size5">e</span><span class="mord mathdefault sizing reset-size6 size5" style="margin-right:0.02691em;">w</span><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5" style="margin-right:0.02778em;">r</span><span class="mord mathdefault sizing reset-size6 size5">d</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.8499999999999999em;vertical-align:-0.7em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">n</span><span class="mord mathdefault sizing reset-size6 size5">e</span><span class="mord mathdefault sizing reset-size6 size5">x</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mspace sizing reset-size6 size5"> </span><span class="mord mathdefault sizing reset-size6 size5">s</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">e</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5" style="margin-right:0.01968em;">l</span><span class="mord mathdefault sizing reset-size6 size5" style="margin-right:0.01968em;">l</span><span class="mspace sizing reset-size6 size5"> </span><span class="mord mathdefault sizing reset-size6 size5">a</span><span class="mord mathdefault sizing reset-size6 size5">c</span><span class="mord mathdefault sizing reset-size6 size5">t</span><span class="mord mathdefault sizing reset-size6 size5">i</span><span class="mord mathdefault sizing reset-size6 size5">o</span><span class="mord mathdefault sizing reset-size6 size5">n</span><span class="mord mathdefault sizing reset-size6 size5">s</span></span><span class="mclose">)</span><span class="mord"><span class="delimsizing size2">)</span></span></span></span></span></span></p>
]]></content>
    </entry>
</feed>