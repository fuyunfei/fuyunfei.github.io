<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://fuyunfei.github.io</id>
    <title>Queen&apos;s Road East</title>
    <updated>2019-10-16T18:38:56.213Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://fuyunfei.github.io"/>
    <link rel="self" href="https://fuyunfei.github.io/atom.xml"/>
    <subtitle>皇后大道西</subtitle>
    <logo>https://fuyunfei.github.io/images/avatar.png</logo>
    <icon>https://fuyunfei.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Queen&apos;s Road East</rights>
    <entry>
        <title type="html"><![CDATA[minimal_LSTM]]></title>
        <id>https://fuyunfei.github.io/post/minimal_lstm</id>
        <link href="https://fuyunfei.github.io/post/minimal_lstm">
        </link>
        <updated>2019-10-16T11:38:10.000Z</updated>
        <summary type="html"><![CDATA[<p>最简单的LSTM</p>
]]></summary>
        <content type="html"><![CDATA[<p>最简单的LSTM</p>
<!-- more -->
<p>import numpy as np</p>
<p>from keras.models import Sequential<br>
from keras.layers import Dense<br>
from keras.layers import LSTM</p>
<p>data = [[i for i in range(100)]]<br>
data = np.array(data, dtype=float)<br>
target = [[i for i in range(1,101)]]<br>
target = np.array(target, dtype=float)</p>
<p>data = data.reshape((1, 1, 100))<br>
target = target.reshape((1, 1, 100))<br>
x_test=[i for i in range(100,200)]<br>
x_test=np.array(x_test).reshape((1,1,100));<br>
y_test=[i for i in range(101,201)]<br>
y_test=np.array(y_test).reshape(1,1,100)</p>
<p>model = Sequential()<br>
model.add(LSTM(100, input_shape=(1, 100),return_sequences=True))<br>
model.add(Dense(100))<br>
model.compile(loss='mean_absolute_error', optimizer='adam',metrics=['accuracy'])<br>
model.fit(data, target, nb_epoch=100, batch_size=1, verbose=2,validation_data=(x_test, y_test))</p>
<p>predict = model.predict(data)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gabor loss]]></title>
        <id>https://fuyunfei.github.io/post/gabor-loss</id>
        <link href="https://fuyunfei.github.io/post/gabor-loss">
        </link>
        <updated>2019-10-16T04:29:47.000Z</updated>
        <content type="html"><![CDATA[<p>使用preset的卷积核作为loss</p>
<pre><code class="language-python">def gabor_kernel_weight(shape):
    # cv2.getGaborKernel(ksize, sigma, theta, lambda, gamma, psi, ktype)
    # ksize - size of gabor filter (n, n)
    # sigma - standard deviation of the gaussian function
    # theta - orientation of the normal to the parallel stripes
    # lambda - wavelength of the sunusoidal factor
    # gamma - spatial aspect ratio
    # psi - phase offset
    # ktype - type and range of values that each pixel in the gabor kernel can hold
    g_kernels = [cv2.getGaborKernel((7, 7), 8.0, i*np.pi/16.0, 5.0, 0.5, 0, ktype=cv2.CV_32F) for i in range(16)]
    g_kernels=np.stack(g_kernels, axis=-1) 
    g_kernels=np.stack([g_kernels, g_kernels , g_kernels],axis=-2) 
    assert g_kernels.shape == shape
    return K.variable(g_kernels, dtype='float32')

def gabor_loss(y_true,y_pred):
    gabor_kernel_weights= gabor_kernel_weight((7,7,3,16)) # 设置 kernel 的 为 7x7x3x16 的gabor filter 
    # b = np.zeros((16,))        
    # garborlayer = Conv2D(16,kernel_size=(7,7),weights=[gabor_kernel_weights,b]) 
    # garborlayer(y_true)
    garbor_true= K.conv2d(y_true,gabor_kernel_weights,padding='same')
    garbor_pred= K.conv2d(y_pred,gabor_kernel_weights,padding='same')
    # Conv2D(16,kernel_size=(7,7),weights=[gabor_kernel_weights,b])(y_true)
    gabor_mse_loss=keras.losses.mean_squared_error(garbor_true,garbor_pred)
    mae_loss =  keras.losses.mean_absolute_error(y_pred,y_true)
    # print('gabor_loss%f  mae_loss%f '% gabor_mse_loss.eval(), mae_loss)
    return mae_loss+0.1*gabor_mse_loss
    ``` 
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tensor Smoothness ]]></title>
        <id>https://fuyunfei.github.io/post/how-to-smooth-the-output-image</id>
        <link href="https://fuyunfei.github.io/post/how-to-smooth-the-output-image">
        </link>
        <updated>2019-09-29T21:36:48.000Z</updated>
        <summary type="html"><![CDATA[<p>Total variation loss could be a solution which basically calculate the gradient of the tensor.</p>
]]></summary>
        <content type="html"><![CDATA[<p>Total variation loss could be a solution which basically calculate the gradient of the tensor.</p>
<!-- more -->
<pre><code class="language-python">    def total_variation(self,x):
        assert K.ndim(x) == 4
        if K.image_data_format() == 'channels_first':
            a = x[:, :, :-1, :- 1] - x[:, :, 1:, :-1]
            b = x[:, :, :-1, :-1] - x[:, :, :-1, 1:]
        else:
            a = x[:, :-1, :-1, :] - x[:, 1:, :-1, :]
            b = x[:, :-1, :-1, :] - x[:, :- 1, 1:, :]
        return K.concatenate((a,b))

    def total_variation_loss(self,x):
        assert K.ndim(x) == 4
        if K.image_data_format() == 'channels_first':
            a = K.square(x[:, :, :-1, :- 1] - x[:, :, 1:, :-1])
            b = K.square(x[:, :, :-1, :-1] - x[:, :, :-1, 1:])
        else:
            a = K.square(x[:, :-1, :-1, :] - x[:, 1:, :-1, :])
            b = K.square( x[:, :-1, :-1, :] - x[:, :- 1, 1:, :])
        return K.sum(K.pow(a + b, 1.25))
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Loss]]></title>
        <id>https://fuyunfei.github.io/post/masked-loss-in-tensorflow</id>
        <link href="https://fuyunfei.github.io/post/masked-loss-in-tensorflow">
        </link>
        <updated>2019-09-29T07:24:17.000Z</updated>
        <summary type="html"><![CDATA[<p>use tf.where to indicate the mask</p>
]]></summary>
        <content type="html"><![CDATA[<p>use tf.where to indicate the mask</p>
<!-- more -->
<pre><code class="language-python">import numpy as np
import tensorflow as tf

'''
 ' Huber loss.
 ' https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/
 ' https://en.wikipedia.org/wiki/Huber_loss
'''
def huber_loss(y_true, y_pred, clip_delta=1.0):
  error = y_true - y_pred
  cond  = tf.keras.backend.abs(error) &lt; clip_delta

  squared_loss = 0.5 * tf.keras.backend.square(error)
  linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)

  return tf.where(cond, squared_loss, linear_loss)

'''
 ' Same as above but returns the mean loss.
'''
def huber_loss_mean(y_true, y_pred, clip_delta=1.0):
  return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))
</code></pre>
]]></content>
    </entry>
</feed>