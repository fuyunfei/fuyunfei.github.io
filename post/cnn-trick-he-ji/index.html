<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>CNN Tricks | 皇后大道中</title>
<meta name="description" content="皇后大道西">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://fuyunfei.github.io/favicon.ico?v=1594817413434">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://fuyunfei.github.io/styles/main.css">



<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>

<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />



  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://fuyunfei.github.io">
        <img src="https://fuyunfei.github.io/images/avatar.png?v=1594817413434" class="site-logo">
        <h1 class="site-title">皇后大道中</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="https://fuyunfei.github.io" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            分类
          </a>
        
      
        
          <a href="http://yunfei.strikingly.com/" class="site-nav" target="_blank">
            关于
          </a>
        
      
        
          <a href="https://fuyunfei.github.io/tag/u69HSrRbn/" class="site-nav">
            画架
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      皇后大道西
    </div>
    <div class="site-footer">
       | <a class="rss" href="https://fuyunfei.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">CNN Tricks</h2>
            <div class="post-date">2020-05-08</div>
            
            <div class="post-content">
              <h1 id="cnn-trick合集">cnn trick合集</h1>
<p>这两天发现了一篇宝藏paper，2019年CVPR中的一篇 <a href="https://link.zhihu.com/?target=http%3A//openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf">Bag of Tricks for Image Classification with Convolutional Neural Networks</a>。 这篇paper主要从3个方面讲述了提高现有baseline(ResNet-50)的有效trick：</p>
<ol>
<li>在新的硬件上有效训练</li>
<li>在ResNet-50的基础上，对模型进行了一些微量的调整</li>
<li>训练的一些技巧</li>
</ol>
<p>大概回顾这篇文章</p>
<h2 id="1-在新的硬件上有效训练">1. 在新的硬件上有效训练</h2>
<h3 id="11-背景">1.1 背景</h3>
<p>在ResNet刚提出的时候，为了考虑当时的硬件条件，不得不做很多跟performance相关的trade-offs。但是随着这几年硬件(尤其是GPU)的快速发展，很多与performance相关的trade-offs已经改变。其中包括：</p>
<ol>
<li>使用更大的batch size。例如从256到1024</li>
<li>使用较低的数值精度。例如从FP32到FP16</li>
</ol>
<h3 id="12-使用更大的batch-size">1.2 使用更大的batch size</h3>
<p>使用更大的batch size会导致减缓训练进度。对于凸问题，收敛速度会随着batch size的增加而降低。也就是说，在相同的epoch下，使用更大的batch size可能会导致验证集accuracy更低。因此使用一些trick来解决这个问题。</p>
<p><strong>Linear scaling learning rate</strong>：例如，当我们选择初始学习率为0.1，batch size为256时，那么当我们将batch size增大至b时，就需要将初始学习率增加曾0.1×b/256</p>
<p><strong>Learning rate warmup</strong>：例如，选择5个epoch去进行warmup，在这5个epoch中线性地从0开始增加学习率至初始学习率，然后再开始正常decay<br>
<strong>Zero</strong> <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-5032a1932221fb26d4520cdc5b09ad46.svg" alt="[公式]" loading="lazy"></p>
<p><strong>No bias decay</strong>：为了避免过拟合，对于权重weight和偏差bias，我们通常会使用weight decay。但在这里，仅对weight使用decay，而不对bias使用decay。</p>
<h3 id="13-使用更低的数值精度">1.3 使用更低的数值精度</h3>
<p>以前神经网络通常使用32-bit浮点数精度(FP32)来训练。但是现在的新的硬件增强了低精度数据类型的算术逻辑单元。例如Nvidia V100对FP32提供14 TFLOPS，而对FP16提供100 TFLOPS。因此，使用FP16时，总的训练速度加速了2~3倍：</p>
<figure data-type="image" tabindex="1"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-29cdfa738a5f43e1450ede322f297e72.jpg" alt="" loading="lazy"></figure>
<p>Comparison of the training time and validation accuracy for ResNet-50 between the baseline (BS=256 with FP32) and a more hardware efficient setting (BS=1024 with FP16).</p>
<figure data-type="image" tabindex="2"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a179819131ee35eb8e7adc45e25e16d6.jpg" alt="" loading="lazy"></figure>
<p>The breakdown effect for each effective training heuristic on ResNet-50.</p>
<h2 id="2-模型调整">2. 模型调整</h2>
<figure data-type="image" tabindex="3"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-96246a2fef83b606b8d755e766807144.jpg" alt="" loading="lazy"></figure>
<p>The architecture of ResNet-50. The convolution kernel size, output channel size and stride size (default is 1) are illustrated, similar for pooling layers.</p>
<p>主要对downsampling block和input steam(上图指出部分)做了一些改动：</p>
<ol>
<li>downsampling做改动主要是由于使用stride=2的1×1 conv会忽略3/4的feature-map。因此，为了使输出的shape保持不变，将path A的前两个conv分别改为stride=1的1×1 conv和stride=2的3×3 conv，即ResNet-C；将path B换成stride=2的2×2 AvgPool和stride=1的1×1 conv，即ResNet-D</li>
<li>而input steam做的改动主要是由于使用7×7 conv的计算cost是3×3的5.4倍。因此将7×7 conv换成3个连续的3×3conv，即ResNet-C</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a678db384db2fb0859cafc51ab31df20.jpg" alt="" loading="lazy"></figure>
<p>Three ResNet tweaks. ResNet-B modifies the downsampling block of Resnet. ResNet-C further modifies the input stem. On top of that, ResNet-D again modifies the downsampling block.</p>
<figure data-type="image" tabindex="5"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-f03f481d9e3ab12a3670fa759a767b1c.jpg" alt="" loading="lazy"></figure>
<p>Compare ResNet-50 with three model tweaks onmodel size, FLOPs and ImageNet validation accuracy.</p>
<h2 id="3-训练技巧">3. 训练技巧</h2>
<h3 id="31-cosine-learning-rate-decay">3.1 Cosine Learning Rate Decay</h3>
<p>以往学习率衰减的策略一般是&quot;step decay&quot;，即每隔一定的epoch，学习率才进行一次指数衰减。而现在，学习率随着epoch的增大不断衰减：</p>
<figure data-type="image" tabindex="6"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-39377e91419ac0e55e9f5fad8570f2a4.jpg" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-80683b364dc1edad22061c0883431c06.jpg" alt="" loading="lazy"></figure>
<p>Visualization of learning rate schedules with warm-up. Top: cosine and step schedules for batch size 1024. Bottom: Top-1 validation accuracy curve with regard to the two schedules.</p>
<h3 id="32-label-smoothing">3.2 Label Smoothing</h3>
<h3 id="33-knowledge-distillation">3.3 Knowledge Distillation</h3>
<h3 id="34-mixup-training">3.4 Mixup Training</h3>
<p>在mixup中，每次随机采样两个样本 <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-6f04414ac44928f5243849659cd507d4.svg" alt="[公式]" loading="lazy"> ，然后通过加权线性插值生成新的样本进行训练：</p>
<figure data-type="image" tabindex="8"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-a38939c6e2718364bc3bb773974e7627.jpg" alt="" loading="lazy"></figure>
<p>其中 <img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-11c2aab6fa911338924d499f8c391345.svg" alt="[公式]" loading="lazy"> 分布的得到的随机数。</p>
<h3 id="35-experiment-results">3.5 Experiment Results</h3>
<figure data-type="image" tabindex="9"><img src="https://fuyunfei.github.io/post-images/cnn-tricks/1588934689-f1595e29466f5dd2c058c840b29adf32.jpg" alt="" loading="lazy"></figure>
<p>The validation accuracies on ImageNet for stacking training refinements one by one. We repeat each refinement on ResNet-50-D for 4 times with different initialization, and report the mean and standard deviation in the table.</p>

            </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://fuyunfei.github.io/post/effective-tensorflow/">
                  <h3 class="post-title">
                    Effective TensorFlow
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>

<script type="application/javascript">

AOS.init();

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>




  </body>
</html>
